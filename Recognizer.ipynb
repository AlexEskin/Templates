{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab's New Code Editor",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexEskin/Templates/blob/master/Recognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKO6rlVGp-sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf crops_train\n",
        "!rm -rf crops_test\n",
        "!rm -rf maps_resized\n",
        "!rm -rf examples\n",
        "\n",
        "!mkdir maps_resized\n",
        "!mkdir crops_train\n",
        "!mkdir crops_test\n",
        "!mkdir examples\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "WIDTH = 224\n",
        "HEIGHT = 224\n",
        "SOURCE = 'MapsExample'\n",
        "\n",
        "def resizeImages():\n",
        "    path_a = SOURCE\n",
        "    path_b = 'maps_resized'\n",
        "\n",
        "    filenames = []\n",
        "    for r, d, f in os.walk(path_a):\n",
        "        for file in f:\n",
        "            if \".png\" in file:\n",
        "               filenames.append(file)\n",
        "    print(filenames)\n",
        "    images = []\n",
        "    minSizeX = None\n",
        "    minSizeY = None\n",
        "\n",
        "    for filename in filenames:\n",
        "        f_a = os.path.join(path_a, filename)\n",
        "        print(f_a)\n",
        "        im_a = cv2.imread(f_a)\n",
        "        if minSizeX != None:\n",
        "            minSizeX = min(minSizeX,im_a.shape[0])\n",
        "        else:\n",
        "            minSizeX = im_a.shape[0]\n",
        "        if minSizeY != None:\n",
        "            minSizeY = min(minSizeY,im_a.shape[1])          \n",
        "        else:\n",
        "            minSizeY = im_a.shape[1]\n",
        "    print(minSizeX,minSizeY)\n",
        "    for filename in filenames:\n",
        "        f_a = os.path.join(path_a, filename)\n",
        "        f_b = os.path.join(path_b, filename)\n",
        "\n",
        "        im_a = cv2.imread(f_a)\n",
        "        crop_img = im_a[0:minSizeX, 0:minSizeY]\n",
        "        cv2.imwrite(f_b,crop_img)\n",
        "\n",
        "def generateCrops():\n",
        "    path_a = 'maps_resized'\n",
        "    path_b = 'crops_train'\n",
        "    path_c = 'crops_test'\n",
        "    examples = 'examples'\n",
        "    filenames = []\n",
        "    for r, d, f in os.walk(path_a):\n",
        "        for file in f:\n",
        "            filenames.append(file)\n",
        "    counter = 0\n",
        "    for filename in filenames:\n",
        "        print(filename)\n",
        "        f_a = os.path.join(path_a, filename)\n",
        "        im_a = cv2.imread(f_a)\n",
        "        shape = im_a.shape\n",
        "        examples_counter = 0\n",
        "        for i in range(0,shape[0]-WIDTH-1,64):\n",
        "            for j in range(0,shape[1]-HEIGHT-1,32):\n",
        "                path = path_b\n",
        "                if not counter%7:\n",
        "                    path = path_c       \n",
        "                submap = os.path.join(path, filename)\n",
        "                try:\n",
        "                  os.mkdir(submap)\n",
        "                except:\n",
        "                  pass\n",
        "                submap = os.path.join(submap,str(counter)+\".png\")\n",
        "                submap_image = im_a[i:i+HEIGHT,j:j+WIDTH]\n",
        "                cv2.imwrite(submap,submap_image)\n",
        "                if examples_counter < 32:\n",
        "                    expath = os.path.join(examples, filename)\n",
        "                    try:\n",
        "                        if not examples_counter:\n",
        "                            os.mkdir(expath)\n",
        "                    except Exception as e:\n",
        "                        pass\n",
        "                    exmap = os.path.join(expath,str(counter)+\".png\")\n",
        "                    cv2.imwrite(exmap,submap_image)\n",
        "                    examples_counter = examples_counter + 1\n",
        "                counter += 1\n",
        "\n",
        "\"\"\"Download maps\"\"\"\n",
        "\n",
        "!rm -rf MapsExample\n",
        "\n",
        "!git clone https://github.com/AlexEskin/MapsExample.git\n",
        "\n",
        "!ls MapsExample\n",
        "\n",
        "resizeImages()\n",
        "generateCrops()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYaTQOzkqJyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import datetime\n",
        "import distutils\n",
        "if distutils.version.LooseVersion(tf.__version__) < '1.14':\n",
        "    raise Exception('This notebook is compatible with TensorFlow 1.14 or higher, for TensorFlow 1.13 or lower please use the previous version at https://github.com/tensorflow/tpu/blob/r1.13/tools/colab/fashion_mnist.ipynb')\n",
        "\n",
        "import pathlib\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "CLASS_CNT = None\n",
        "\n",
        "def generate_dataset(dir):\n",
        "  global CLASS_CNT\n",
        "  data_root = pathlib.Path(dir)\n",
        "  label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
        "  if CLASS_CNT == None:\n",
        "    CLASS_CNT = len(label_names)\n",
        "    \n",
        "  all_image_paths = list(data_root.glob('*/*'))\n",
        "  all_image_paths = [str(path) for path in all_image_paths]\n",
        "  random.shuffle(all_image_paths)\n",
        "\n",
        "  label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
        "  label_to_index = dict((name, index) for index,name in enumerate(label_names))\n",
        "\n",
        "  all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
        "                      for path in all_image_paths]\n",
        "  print(\"First 10 labels indices: \", all_image_labels[:10])\n",
        "\n",
        "  return (all_image_paths,all_image_labels)\n",
        "\n",
        "dataset = generate_dataset(\"crops_train\")\n",
        "test_dataset = generate_dataset(\"crops_test\")\n",
        "\n",
        "def tr_generator(n):\n",
        "  num = 0\n",
        "  while num < n:\n",
        "    id = random.randint(0,len(dataset[0])-1)\n",
        "    img = cv2.imread(dataset[0][id],cv2.IMREAD_GRAYSCALE)\n",
        "    img = np.expand_dims(img, -1).astype(np.float32)\n",
        "    yield img*(1/255.0), dataset[1][id]\n",
        "    num += 1\n",
        "    \n",
        "    \n",
        "def t_generator(n):\n",
        "  num = 0\n",
        "  while num < n:\n",
        "    id = random.randint(0,len(test_dataset[0])-1)\n",
        "    img = cv2.imread(test_dataset[0][id],cv2.IMREAD_GRAYSCALE)\n",
        "    img = np.expand_dims(img, -1).astype(np.float32)\n",
        "    yield img*(1/255.0), test_dataset[1][id]\n",
        "    num += 1\n",
        "    \n",
        "\n",
        "input_data = dataset[0][0]\n",
        "\n",
        "input_data = cv2.imread(input_data,cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
        "input_data = np.expand_dims(input_data, -1)\n",
        "input_data_shape = input_data.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfzlfqTOqehC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "strategy = None\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  resolver = tf.contrib.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "  tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "  strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
        "\n",
        "def create_model_vgg19():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  drop = 0.5\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=input_data_shape))\n",
        "  model.add(tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "  # model.add(tf.keras.layers.Dropout(drop))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "    \n",
        "  model.add(tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "  # model.add(tf.keras.layers.Dropout(drop))\n",
        "  # model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "  # model.add(tf.keras.layers.Dropout(drop))\n",
        "  # model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "  # model.add(tf.keras.layers.Dropout(drop))\n",
        "  # model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "  # model.add(tf.keras.layers.Dropout(drop))\n",
        "  # model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "\n",
        "  #model.add(tf.keras.layers.Dense(256))\n",
        "  #model.add(tf.keras.layers.Activation('elu'))  \n",
        "  #model.add(tf.keras.layers.BatchNormalization())\n",
        "  #model.add(tf.keras.layers.Dropout(drop))\n",
        "  \n",
        "  model.add(tf.keras.layers.Dense(CLASS_CNT,activation='softmax'))\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "def create_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  drop = 0.5\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=input_data_shape))\n",
        "  model.add(tf.keras.layers.Conv2D(64, (9, 9), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(128, (9, 9), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=input_data_shape))\n",
        "  model.add(tf.keras.layers.Conv2D(96, (7, 7), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(192, (7, 7), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=input_data_shape))\n",
        "  model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=input_data_shape))\n",
        "  model.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "  \n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(1024))\n",
        "  model.add(tf.keras.layers.Activation('elu'))\n",
        "  model.add(tf.keras.layers.Dense(256))\n",
        "  model.add(tf.keras.layers.Activation('elu'))  \n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "  model.add(tf.keras.layers.Dense(CLASS_CNT,activation='softmax'))\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "if strategy != None:\n",
        "  with strategy.scope():\n",
        "    model = create_model_vgg19()\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adadelta( ),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['sparse_categorical_accuracy'])\n",
        "else:\n",
        "    model = create_model_vgg19()\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adadelta( ),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['sparse_categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygRwitPNqiES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "try:\n",
        "  model.load_weights('/content/drive/My Drive/vgg19_1.h5')\n",
        "except:\n",
        "  print(\"Unable to load weights...\")\n",
        "  pass\n",
        "batch_size = 32\n",
        "data_length = (len(dataset[0])//batch_size)*batch_size\n",
        "print(\"Data lenght = \", data_length)\n",
        "for i in range(10):\n",
        "  training_generator = tr_generator(data_length)\n",
        "  #\n",
        "  # validation_generator = t_generator(200)\n",
        "  model.save_weights('/content/drive/My Drive/vgg19_1.h5', overwrite=True)\n",
        "  train_xy =list(zip(*training_generator))\n",
        "  print(\"train ready\")\n",
        "  # test_xy = list(zip(*validation_generator))\n",
        "  # print(\"validation ready\")\n",
        "  train_xy = (np.array(train_xy[0]).astype(np.float32),np.array(train_xy[1]).astype(np.float32))\n",
        "  # test_xy = (np.array(test_xy[0]).astype(np.float32),np.array(test_xy[1]).astype(np.float32))\n",
        "  print(\"fitting\")\n",
        "  history = model.fit(\n",
        "      train_xy[0],train_xy[1],\n",
        "      epochs=20,\n",
        "      #steps_per_epoch=416*10//8#13*10\n",
        "      batch_size=batch_size\n",
        "  )\n",
        "  \n",
        "  print(datetime.datetime.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohlbg7z1k7_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_generator = t_generator(200)\n",
        "test_xy = list(zip(*validation_generator))\n",
        "result = model.predict(np.array(test_xy[0]).astype(np.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KWGmBYVlzNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos = 0\n",
        "for i in range(len(result)):\n",
        "  test_y = result[i].argmax()\n",
        "  valid_y = test_xy[1][i]\n",
        "  print(test_y, valid_y, test_y==valid_y)\n",
        "  pos += (test_y==valid_y)\n",
        "print(pos/len(result))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}