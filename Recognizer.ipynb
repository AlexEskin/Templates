{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab's New Code Editor",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexEskin/Templates/blob/master/Recognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKO6rlVGp-sk",
        "colab_type": "code",
        "outputId": "1f8393b5-eeb4-4e4f-883a-0b9e99eeadec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!rm -rf crops_train\n",
        "!rm -rf crops_test\n",
        "!rm -rf maps_resized\n",
        "!rm -rf examples\n",
        "\n",
        "!mkdir maps_resized\n",
        "!mkdir crops_train\n",
        "!mkdir crops_test\n",
        "!mkdir examples\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "WIDTH = 256\n",
        "HEIGHT = 256\n",
        "SOURCE = 'MapsExample'\n",
        "\n",
        "def resizeImages():\n",
        "    path_a = SOURCE\n",
        "    path_b = 'maps_resized'\n",
        "\n",
        "    filenames = []\n",
        "    for r, d, f in os.walk(path_a):\n",
        "        for file in f:\n",
        "            if \".png\" in file:\n",
        "               filenames.append(file)\n",
        "    print(filenames)\n",
        "    images = []\n",
        "    minSizeX = None\n",
        "    minSizeY = None\n",
        "\n",
        "    for filename in filenames:\n",
        "        f_a = os.path.join(path_a, filename)\n",
        "        print(f_a)\n",
        "        im_a = cv2.imread(f_a)\n",
        "        if minSizeX != None:\n",
        "            minSizeX = min(minSizeX,im_a.shape[0])\n",
        "        else:\n",
        "            minSizeX = im_a.shape[0]\n",
        "        if minSizeY != None:\n",
        "            minSizeY = min(minSizeY,im_a.shape[1])          \n",
        "        else:\n",
        "            minSizeY = im_a.shape[1]\n",
        "    print(minSizeX,minSizeY)\n",
        "    for filename in filenames:\n",
        "        f_a = os.path.join(path_a, filename)\n",
        "        f_b = os.path.join(path_b, filename)\n",
        "\n",
        "        im_a = cv2.imread(f_a)\n",
        "        crop_img = im_a[0:minSizeX, 0:minSizeY]\n",
        "        cv2.imwrite(f_b,crop_img)\n",
        "\n",
        "def generateCrops():\n",
        "    path_a = 'maps_resized'\n",
        "    path_b = 'crops_train'\n",
        "    path_c = 'crops_test'\n",
        "    examples = 'examples'\n",
        "    filenames = []\n",
        "    for r, d, f in os.walk(path_a):\n",
        "        for file in f:\n",
        "            filenames.append(file)\n",
        "    counter = 0\n",
        "    for filename in filenames:\n",
        "        f_a = os.path.join(path_a, filename)\n",
        "        im_a = cv2.imread(f_a)\n",
        "        shape = im_a.shape\n",
        "        examples_counter = 0\n",
        "        for i in range(0,shape[0]-WIDTH-1,64):\n",
        "            for j in range(0,shape[1]-HEIGHT-1,64):\n",
        "                path = path_b\n",
        "                if not counter%7:\n",
        "                    path = path_c       \n",
        "                submap = os.path.join(path, filename)\n",
        "                try:\n",
        "                  os.mkdir(submap)\n",
        "                except:\n",
        "                  pass\n",
        "                submap = os.path.join(submap,str(counter)+\".png\")\n",
        "                submap_image = im_a[i:i+HEIGHT,j:j+WIDTH]\n",
        "                cv2.imwrite(submap,submap_image)\n",
        "                if examples_counter < 32:\n",
        "                    expath = os.path.join(examples, filename)\n",
        "                    try:\n",
        "                        if not examples_counter:\n",
        "                            os.mkdir(expath)\n",
        "                    except Exception as e:\n",
        "                        pass\n",
        "                    exmap = os.path.join(expath,str(counter)+\".png\")\n",
        "                    cv2.imwrite(exmap,submap_image)\n",
        "                    examples_counter = examples_counter + 1\n",
        "                counter += 1\n",
        "\n",
        "\"\"\"Download maps\"\"\"\n",
        "\n",
        "!rm -rf MapsExample\n",
        "\n",
        "!git clone https://github.com/AlexEskin/MapsExample.git\n",
        "\n",
        "!ls MapsExample\n",
        "\n",
        "resizeImages()\n",
        "generateCrops()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MapsExample'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 55 (delta 0), reused 55 (delta 0), pack-reused 0\n",
            "Unpacking objects: 100% (55/55), done.\n",
            "map_10.png  map_19.png\tmap_27.png  map_35.png\tmap_43.png  map_5.png\n",
            "map_11.png  map_1.png\tmap_28.png  map_36.png\tmap_44.png  map_6.png\n",
            "map_12.png  map_20.png\tmap_29.png  map_37.png\tmap_45.png  map_7.png\n",
            "map_13.png  map_21.png\tmap_2.png   map_38.png\tmap_46.png  map_8.png\n",
            "map_14.png  map_22.png\tmap_30.png  map_39.png\tmap_47.png  map_9.png\n",
            "map_15.png  map_23.png\tmap_31.png  map_3.png\tmap_48.png  README.md\n",
            "map_16.png  map_24.png\tmap_32.png  map_40.png\tmap_49.png\n",
            "map_17.png  map_25.png\tmap_33.png  map_41.png\tmap_4.png\n",
            "map_18.png  map_26.png\tmap_34.png  map_42.png\tmap_50.png\n",
            "['map_50.png', 'map_31.png', 'map_29.png', 'map_23.png', 'map_12.png', 'map_14.png', 'map_1.png', 'map_21.png', 'map_34.png', 'map_2.png', 'map_42.png', 'map_17.png', 'map_4.png', 'map_7.png', 'map_37.png', 'map_24.png', 'map_18.png', 'map_45.png', 'map_16.png', 'map_11.png', 'map_30.png', 'map_10.png', 'map_48.png', 'map_44.png', 'map_39.png', 'map_36.png', 'map_22.png', 'map_13.png', 'map_40.png', 'map_3.png', 'map_28.png', 'map_5.png', 'map_19.png', 'map_25.png', 'map_38.png', 'map_20.png', 'map_49.png', 'map_33.png', 'map_8.png', 'map_46.png', 'map_6.png', 'map_32.png', 'map_41.png', 'map_26.png', 'map_43.png', 'map_35.png', 'map_9.png', 'map_47.png', 'map_27.png', 'map_15.png']\n",
            "MapsExample/map_50.png\n",
            "MapsExample/map_31.png\n",
            "MapsExample/map_29.png\n",
            "MapsExample/map_23.png\n",
            "MapsExample/map_12.png\n",
            "MapsExample/map_14.png\n",
            "MapsExample/map_1.png\n",
            "MapsExample/map_21.png\n",
            "MapsExample/map_34.png\n",
            "MapsExample/map_2.png\n",
            "MapsExample/map_42.png\n",
            "MapsExample/map_17.png\n",
            "MapsExample/map_4.png\n",
            "MapsExample/map_7.png\n",
            "MapsExample/map_37.png\n",
            "MapsExample/map_24.png\n",
            "MapsExample/map_18.png\n",
            "MapsExample/map_45.png\n",
            "MapsExample/map_16.png\n",
            "MapsExample/map_11.png\n",
            "MapsExample/map_30.png\n",
            "MapsExample/map_10.png\n",
            "MapsExample/map_48.png\n",
            "MapsExample/map_44.png\n",
            "MapsExample/map_39.png\n",
            "MapsExample/map_36.png\n",
            "MapsExample/map_22.png\n",
            "MapsExample/map_13.png\n",
            "MapsExample/map_40.png\n",
            "MapsExample/map_3.png\n",
            "MapsExample/map_28.png\n",
            "MapsExample/map_5.png\n",
            "MapsExample/map_19.png\n",
            "MapsExample/map_25.png\n",
            "MapsExample/map_38.png\n",
            "MapsExample/map_20.png\n",
            "MapsExample/map_49.png\n",
            "MapsExample/map_33.png\n",
            "MapsExample/map_8.png\n",
            "MapsExample/map_46.png\n",
            "MapsExample/map_6.png\n",
            "MapsExample/map_32.png\n",
            "MapsExample/map_41.png\n",
            "MapsExample/map_26.png\n",
            "MapsExample/map_43.png\n",
            "MapsExample/map_35.png\n",
            "MapsExample/map_9.png\n",
            "MapsExample/map_47.png\n",
            "MapsExample/map_27.png\n",
            "MapsExample/map_15.png\n",
            "831 1461\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYaTQOzkqJyE",
        "colab_type": "code",
        "outputId": "549a0a71-85fa-46a1-dbe2-9d4a78d7c287",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import datetime\n",
        "import distutils\n",
        "if distutils.version.LooseVersion(tf.__version__) < '1.14':\n",
        "    raise Exception('This notebook is compatible with TensorFlow 1.14 or higher, for TensorFlow 1.13 or lower please use the previous version at https://github.com/tensorflow/tpu/blob/r1.13/tools/colab/fashion_mnist.ipynb')\n",
        "\n",
        "import pathlib\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "CLASS_CNT = None\n",
        "\n",
        "def generate_dataset(dir):\n",
        "  global CLASS_CNT\n",
        "  data_root = pathlib.Path(dir)\n",
        "  label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
        "  if CLASS_CNT == None:\n",
        "    CLASS_CNT = len(label_names)\n",
        "    \n",
        "  all_image_paths = list(data_root.glob('*/*'))\n",
        "  all_image_paths = [str(path) for path in all_image_paths]\n",
        "  random.shuffle(all_image_paths)\n",
        "\n",
        "  label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
        "  label_to_index = dict((name, index) for index,name in enumerate(label_names))\n",
        "\n",
        "  all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
        "                      for path in all_image_paths]\n",
        "  print(\"First 10 labels indices: \", all_image_labels[:10])\n",
        "\n",
        "  return (all_image_paths,all_image_labels)\n",
        "\n",
        "dataset = generate_dataset(\"crops_train\")\n",
        "test_dataset = generate_dataset(\"crops_test\")\n",
        "\n",
        "def tr_generator(n):\n",
        "  num = 0\n",
        "  id = random.randint(0,len(dataset[0])*65535)\n",
        "  while num < n:\n",
        "    id %= len(dataset[0])\n",
        "    img = cv2.imread(dataset[0][id],cv2.IMREAD_GRAYSCALE)\n",
        "    img = np.expand_dims(img, -1).astype(np.float32)\n",
        "    yield img*(1/255.0), dataset[1][id]\n",
        "    num += 1\n",
        "    id += 1\n",
        "    \n",
        "    \n",
        "def t_generator(n):\n",
        "  num = 0\n",
        "  id = random.randint(0,len(dataset[0])*65535)\n",
        "  while num < n:\n",
        "    id %= len(test_dataset[0])\n",
        "    img = cv2.imread(test_dataset[0][id],cv2.IMREAD_GRAYSCALE)\n",
        "    img = np.expand_dims(img, -1).astype(np.float32)\n",
        "    yield img*(1/255.0), test_dataset[1][id]\n",
        "    num += 1\n",
        "    id += 1\n",
        "    \n",
        "\n",
        "input_data = dataset[0][0]\n",
        "input_data = cv2.imread(input_data,cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
        "input_data = np.expand_dims(input_data, -1)\n",
        "input_data_shape = input_data.shape\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 10 labels indices:  [46, 16, 17, 12, 1, 37, 35, 31, 2, 5]\n",
            "First 10 labels indices:  [13, 9, 31, 14, 39, 0, 26, 47, 46, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfzlfqTOqehC",
        "colab_type": "code",
        "outputId": "0d2c1937-75b1-45fc-db70-48a094df4aff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "\n",
        "strategy = None\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  resolver = tf.contrib.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "  tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "  strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
        "\n",
        "def create_model_vgg19():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  drop = 0.2\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=input_data_shape))\n",
        "  model.add(tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(tf.keras.layers.Dropout(drop))  \n",
        "  model.add(tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "  model.add(tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(1024))\n",
        "  model.add(tf.keras.layers.Activation('elu'))\n",
        "  model.add(tf.keras.layers.Dense(256))\n",
        "  model.add(tf.keras.layers.Activation('elu'))  \n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "  model.add(tf.keras.layers.Dense(CLASS_CNT))\n",
        "  model.add(tf.keras.layers.Activation('softmax'))\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "def create_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  drop = 0.2\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=input_data_shape))\n",
        "  model.add(tf.keras.layers.Conv2D(64, (9, 9), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(128, (9, 9), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=input_data_shape))\n",
        "  model.add(tf.keras.layers.Conv2D(96, (7, 7), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(192, (7, 7), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=input_data_shape))\n",
        "  model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=input_data_shape))\n",
        "  model.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "  \n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(1024))\n",
        "  model.add(tf.keras.layers.Activation('elu'))\n",
        "  model.add(tf.keras.layers.Dense(256))\n",
        "  model.add(tf.keras.layers.Activation('elu'))  \n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "  model.add(tf.keras.layers.Dense(CLASS_CNT))\n",
        "  model.add(tf.keras.layers.Activation('softmax'))\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "if strategy != None:\n",
        "  with strategy.scope():\n",
        "    model = create_model()\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adadelta( ),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['sparse_categorical_accuracy'])\n",
        "else:\n",
        "    model = create_model()\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adadelta( ),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['sparse_categorical_accuracy'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Initializing the TPU system.\n",
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.46.87.18:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 12031864767707300793)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 12463054145494924263)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 6103222464848982332)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 8242181672009685281)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 11058254443163193041)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4407318975204530743)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 6422749599294957353)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 14732921416362544838)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 5925174392006291873)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 1229709717090618678)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 5455238871126517454)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 256, 256, 1)       4         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 256, 256, 64)      5248      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 256, 256, 128)     663680    \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 128, 128, 128)     0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128, 128, 128)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 128, 128, 128)     512       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 128, 128, 96)      602208    \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 128, 128, 192)     903360    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 192)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64, 64, 192)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 64, 64, 192)       768       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 64, 64, 128)       614528    \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 64, 64, 256)       819456    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32, 32, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 128)       295040    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              33555456  \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                12850     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 50)                0         \n",
            "=================================================================\n",
            "Total params: 37,736,534\n",
            "Trainable params: 37,735,380\n",
            "Non-trainable params: 1,154\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygRwitPNqiES",
        "colab_type": "code",
        "outputId": "4e101e33-db74-47ae-8cdf-083c327fca71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "while True:\n",
        "  training_generator = tr_generator(4160)\n",
        "  model.load_weights('/content/drive/My Drive/fashion_mnist.h5')\n",
        "  # validation_generator = t_generator(200)\n",
        "  model.save_weights('/content/drive/My Drive/fashion_mnist.h5', overwrite=True)\n",
        "  train_xy =list(zip(*training_generator))\n",
        "  print(\"train ready\")\n",
        "  # test_xy = list(zip(*validation_generator))\n",
        "  # print(\"validation ready\")\n",
        "  train_xy = (np.array(train_xy[0]).astype(np.float32),np.array(train_xy[1]).astype(np.float32))\n",
        "  # test_xy = (np.array(test_xy[0]).astype(np.float32),np.array(test_xy[1]).astype(np.float32))\n",
        "  print(\"fitting\")\n",
        "  history = model.fit(\n",
        "      train_xy[0],train_xy[1],\n",
        "      epochs=75,\n",
        "      steps_per_epoch=13\n",
        "  )\n",
        "  \n",
        "  print(datetime.datetime.now())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "train ready\n",
            "fitting\n",
            "Epoch 1/75\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_distributed.py:411: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "13/13 [==============================] - 38s 3s/step - loss: 0.7485 - sparse_categorical_accuracy: 0.7399\n",
            "Epoch 2/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.7029 - sparse_categorical_accuracy: 0.7522\n",
            "Epoch 3/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6878 - sparse_categorical_accuracy: 0.7603\n",
            "Epoch 4/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.7072 - sparse_categorical_accuracy: 0.7558\n",
            "Epoch 5/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6983 - sparse_categorical_accuracy: 0.7529\n",
            "Epoch 6/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6878 - sparse_categorical_accuracy: 0.7625\n",
            "Epoch 7/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.7173 - sparse_categorical_accuracy: 0.7495\n",
            "Epoch 8/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6780 - sparse_categorical_accuracy: 0.7611\n",
            "Epoch 9/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.7100 - sparse_categorical_accuracy: 0.7591\n",
            "Epoch 10/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6641 - sparse_categorical_accuracy: 0.7661\n",
            "Epoch 11/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6823 - sparse_categorical_accuracy: 0.7555\n",
            "Epoch 12/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6745 - sparse_categorical_accuracy: 0.7642\n",
            "Epoch 13/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6457 - sparse_categorical_accuracy: 0.7731\n",
            "Epoch 14/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6627 - sparse_categorical_accuracy: 0.7707\n",
            "Epoch 15/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6731 - sparse_categorical_accuracy: 0.7632\n",
            "Epoch 16/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6840 - sparse_categorical_accuracy: 0.7649\n",
            "Epoch 17/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6498 - sparse_categorical_accuracy: 0.7788\n",
            "Epoch 18/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6579 - sparse_categorical_accuracy: 0.7678\n",
            "Epoch 19/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6374 - sparse_categorical_accuracy: 0.7810\n",
            "Epoch 20/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6245 - sparse_categorical_accuracy: 0.7863\n",
            "Epoch 21/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6080 - sparse_categorical_accuracy: 0.7918\n",
            "Epoch 22/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6604 - sparse_categorical_accuracy: 0.7688\n",
            "Epoch 23/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6479 - sparse_categorical_accuracy: 0.7784\n",
            "Epoch 24/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6265 - sparse_categorical_accuracy: 0.7709\n",
            "Epoch 25/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6321 - sparse_categorical_accuracy: 0.7851\n",
            "Epoch 26/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6346 - sparse_categorical_accuracy: 0.7772\n",
            "Epoch 27/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6212 - sparse_categorical_accuracy: 0.7837\n",
            "Epoch 28/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6371 - sparse_categorical_accuracy: 0.7743\n",
            "Epoch 29/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6103 - sparse_categorical_accuracy: 0.7892\n",
            "Epoch 30/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6268 - sparse_categorical_accuracy: 0.7822\n",
            "Epoch 31/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6049 - sparse_categorical_accuracy: 0.7846\n",
            "Epoch 32/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6610 - sparse_categorical_accuracy: 0.7673\n",
            "Epoch 33/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6210 - sparse_categorical_accuracy: 0.7899\n",
            "Epoch 34/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6232 - sparse_categorical_accuracy: 0.7829\n",
            "Epoch 35/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5984 - sparse_categorical_accuracy: 0.8029\n",
            "Epoch 36/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5859 - sparse_categorical_accuracy: 0.8012\n",
            "Epoch 37/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6272 - sparse_categorical_accuracy: 0.7800\n",
            "Epoch 38/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6125 - sparse_categorical_accuracy: 0.7849\n",
            "Epoch 39/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6203 - sparse_categorical_accuracy: 0.7793\n",
            "Epoch 40/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6175 - sparse_categorical_accuracy: 0.7868\n",
            "Epoch 41/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5866 - sparse_categorical_accuracy: 0.7983\n",
            "Epoch 42/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5784 - sparse_categorical_accuracy: 0.8000\n",
            "Epoch 43/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5747 - sparse_categorical_accuracy: 0.7957\n",
            "Epoch 44/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6202 - sparse_categorical_accuracy: 0.7846\n",
            "Epoch 45/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5715 - sparse_categorical_accuracy: 0.8031\n",
            "Epoch 46/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5751 - sparse_categorical_accuracy: 0.8026\n",
            "Epoch 47/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6065 - sparse_categorical_accuracy: 0.7911\n",
            "Epoch 48/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5897 - sparse_categorical_accuracy: 0.7988\n",
            "Epoch 49/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.6118 - sparse_categorical_accuracy: 0.7880\n",
            "Epoch 50/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5753 - sparse_categorical_accuracy: 0.7969\n",
            "Epoch 51/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5237 - sparse_categorical_accuracy: 0.8192\n",
            "Epoch 52/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5639 - sparse_categorical_accuracy: 0.8031\n",
            "Epoch 53/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5511 - sparse_categorical_accuracy: 0.8111\n",
            "Epoch 54/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5599 - sparse_categorical_accuracy: 0.8072\n",
            "Epoch 55/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5544 - sparse_categorical_accuracy: 0.8101\n",
            "Epoch 56/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5853 - sparse_categorical_accuracy: 0.7942\n",
            "Epoch 57/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5664 - sparse_categorical_accuracy: 0.8014\n",
            "Epoch 58/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5416 - sparse_categorical_accuracy: 0.8115\n",
            "Epoch 59/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5525 - sparse_categorical_accuracy: 0.8103\n",
            "Epoch 60/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5350 - sparse_categorical_accuracy: 0.8171\n",
            "Epoch 61/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5288 - sparse_categorical_accuracy: 0.8118\n",
            "Epoch 62/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5427 - sparse_categorical_accuracy: 0.8082\n",
            "Epoch 63/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5283 - sparse_categorical_accuracy: 0.8175\n",
            "Epoch 64/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5348 - sparse_categorical_accuracy: 0.8159\n",
            "Epoch 65/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5464 - sparse_categorical_accuracy: 0.8103\n",
            "Epoch 66/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5191 - sparse_categorical_accuracy: 0.8168\n",
            "Epoch 67/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5233 - sparse_categorical_accuracy: 0.8168\n",
            "Epoch 68/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5241 - sparse_categorical_accuracy: 0.8207\n",
            "Epoch 69/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5355 - sparse_categorical_accuracy: 0.8190\n",
            "Epoch 70/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5096 - sparse_categorical_accuracy: 0.8219\n",
            "Epoch 71/75\n",
            "13/13 [==============================] - 21s 2s/step - loss: 0.5193 - sparse_categorical_accuracy: 0.8248\n",
            "Epoch 72/75\n",
            " 5/13 [==========>...................] - ETA: 12s - loss: 0.5232 - sparse_categorical_accuracy: 0.8250"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK_BMXfEGzTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIV84PbOCu6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('fashion_mnist.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}