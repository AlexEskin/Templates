{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab's New Code Editor",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexEskin/Templates/blob/master/Recognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKO6rlVGp-sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf crops_train\n",
        "!rm -rf crops_test\n",
        "!rm -rf maps_resized\n",
        "!rm -rf examples\n",
        "\n",
        "!mkdir maps_resized\n",
        "!mkdir crops_train\n",
        "!mkdir crops_test\n",
        "!mkdir examples\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import files\n",
        "import random\n",
        "WIDTH = 224\n",
        "HEIGHT = 224\n",
        "SOURCE = 'MapsExample'\n",
        "\n",
        "def resizeImages():\n",
        "    path_a = SOURCE\n",
        "    path_b = 'maps_resized'\n",
        "\n",
        "    filenames = []\n",
        "    for r, d, f in os.walk(path_a):\n",
        "        for file in f:\n",
        "            if \".png\" in file:\n",
        "               filenames.append(file)\n",
        "    print(filenames)\n",
        "    images = []\n",
        "    minSizeX = None\n",
        "    minSizeY = None\n",
        "\n",
        "    for filename in filenames:\n",
        "        f_a = os.path.join(path_a, filename)\n",
        "        print(f_a)\n",
        "        im_a = cv2.imread(f_a)\n",
        "        if minSizeX != None:\n",
        "            minSizeX = min(minSizeX,im_a.shape[0])\n",
        "        else:\n",
        "            minSizeX = im_a.shape[0]\n",
        "        if minSizeY != None:\n",
        "            minSizeY = min(minSizeY,im_a.shape[1])          \n",
        "        else:\n",
        "            minSizeY = im_a.shape[1]\n",
        "    print(minSizeX,minSizeY)\n",
        "    for filename in filenames:\n",
        "        f_a = os.path.join(path_a, filename)\n",
        "        f_b = os.path.join(path_b, filename)\n",
        "\n",
        "        im_a = cv2.imread(f_a)\n",
        "        crop_img = im_a[0:minSizeX, 0:minSizeY]\n",
        "        cv2.imwrite(f_b,crop_img)\n",
        "\n",
        "def generateCrops():\n",
        "    path_a = 'maps_resized'\n",
        "    path_b = 'crops_train'\n",
        "    path_c = 'crops_test'\n",
        "    examples = 'examples'\n",
        "    filenames = []\n",
        "    for r, d, f in os.walk(path_a):\n",
        "        for file in f:\n",
        "            filenames.append(file)\n",
        "    counter = 0\n",
        "    for filename in filenames:\n",
        "        print(filename)\n",
        "        f_a = os.path.join(path_a, filename)\n",
        "        im_a = cv2.imread(f_a)\n",
        "        shape = im_a.shape\n",
        "        examples_counter = 0\n",
        "        for i in range(0,shape[0]-WIDTH-1,32):\n",
        "            for j in range(0,shape[1]-HEIGHT-1,16):\n",
        "                path = path_b\n",
        "                if not counter%7:\n",
        "                    path = path_c       \n",
        "                submap = os.path.join(path, filename)\n",
        "                try:\n",
        "                  os.mkdir(submap)\n",
        "                except:\n",
        "                  pass\n",
        "                submap = os.path.join(submap,str(counter)+\".png\")\n",
        "\n",
        "                submap_image = im_a[i:i+WIDTH,j:j+HEIGHT]\n",
        "                cv2.imwrite(submap,submap_image)\n",
        "                if examples_counter < 32:\n",
        "                    expath = os.path.join(examples, filename)\n",
        "                    try:\n",
        "                        if not examples_counter:\n",
        "                            os.mkdir(expath)\n",
        "                    except Exception as e:\n",
        "                        pass\n",
        "                    exmap = os.path.join(expath,str(counter)+\".png\")\n",
        "                    cv2.imwrite(exmap,submap_image)\n",
        "                    examples_counter = examples_counter + 1\n",
        "                counter += 1\n",
        "\n",
        "\"\"\"Download maps\"\"\"\n",
        "\n",
        "!rm -rf MapsExample\n",
        "\n",
        "!git clone https://github.com/AlexEskin/MapsExample.git\n",
        "\n",
        "!ls MapsExample\n",
        "\n",
        "resizeImages()\n",
        "generateCrops()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYaTQOzkqJyE",
        "colab_type": "code",
        "outputId": "8d6a66bd-e8f9-4952-d4ad-ae600b61ae5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import datetime\n",
        "import distutils\n",
        "if distutils.version.LooseVersion(tf.__version__) < '1.14':\n",
        "    raise Exception('This notebook is compatible with TensorFlow 1.14 or higher, for TensorFlow 1.13 or lower please use the previous version at https://github.com/tensorflow/tpu/blob/r1.13/tools/colab/fashion_mnist.ipynb')\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "CLASS_CNT = None\n",
        "\n",
        "def generate_dataset(dir):\n",
        "  global CLASS_CNT\n",
        "  data_root = pathlib.Path(dir)\n",
        "  label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
        "  if CLASS_CNT == None:\n",
        "    CLASS_CNT = len(label_names)\n",
        "    \n",
        "  all_image_paths = list(data_root.glob('*/*'))\n",
        "  all_image_paths = [str(path) for path in all_image_paths]\n",
        "  random.shuffle(all_image_paths)\n",
        "\n",
        "  label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
        "  label_to_index = dict((name, index) for index,name in enumerate(label_names))\n",
        "\n",
        "  all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
        "                      for path in all_image_paths]\n",
        "  print(\"First 10 labels indices: \", all_image_labels[:10])\n",
        "\n",
        "  return (all_image_paths,all_image_labels)\n",
        "\n",
        "dataset = generate_dataset(\"crops_train\")\n",
        "test_dataset = generate_dataset(\"crops_test\")\n",
        "   \n",
        "def t_generator(n):\n",
        "  num = 0\n",
        "  while num < n:\n",
        "    id = random.randint(0,len(test_dataset[0])-1)\n",
        "    img = cv2.imread(test_dataset[0][id],cv2.IMREAD_GRAYSCALE)\n",
        "    img = np.expand_dims(img, -1).astype(np.float32)\n",
        "    yield img*(1/255.0), test_dataset[1][id]\n",
        "    num += 1\n",
        "    \n",
        "\n",
        "input_data = dataset[0][0]\n",
        "\n",
        "input_data = cv2.imread(input_data,cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
        "input_data = np.expand_dims(input_data, -1)\n",
        "input_data_shape = input_data.shape\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 10 labels indices:  [48, 31, 19, 14, 31, 40, 19, 2, 22, 25]\n",
            "First 10 labels indices:  [44, 11, 43, 19, 6, 6, 22, 28, 28, 47]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koFPFbYzQ3AX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "    filters1, filters2, filters3 = filters\n",
        "    #if backend.image_data_format() == 'channels_last':\n",
        "    bn_axis = 3\n",
        "    #else:\n",
        "    #    bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters1, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a')(input_tensor)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters2, kernel_size,\n",
        "                      padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    x = tf.keras.layers.add([x, input_tensor])\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block(input_tensor,\n",
        "               kernel_size,\n",
        "               filters,\n",
        "               stage,\n",
        "               block,\n",
        "               strides=(2, 2)):\n",
        "\n",
        "    filters1, filters2, filters3 = filters\n",
        "    bn_axis = 3\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters1, (1, 1), strides=strides,\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a')(input_tensor)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    shortcut = tf.keras.layers.Conv2D(filters3, (1, 1), strides=strides,\n",
        "                             kernel_initializer='he_normal',\n",
        "                             name=conv_name_base + '1')(input_tensor)\n",
        "    shortcut = tf.keras.layers.BatchNormalization(\n",
        "        axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = tf.keras.layers.add([x, shortcut])\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def create_model_ResNet50(input_shape=(224,224,1)):\n",
        "    img_input = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = tf.keras.layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n",
        "    x = tf.keras.layers.Conv2D(64, (7, 7),\n",
        "                      strides=(2, 2),\n",
        "                      padding='valid',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name='conv1')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis = 3,name='bn_conv1')(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    x = tf.keras.layers.ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n",
        "    x = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(CLASS_CNT,activation='softmax')(x)\n",
        "    model = tf.keras.models.Model(img_input, x, name='resnet50')\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfzlfqTOqehC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "strategy = None\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  resolver = tf.contrib.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "  tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "  strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
        "\n",
        "def create_model_vgg19():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  drop = 0.5\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=input_data_shape))\n",
        "  model.add(tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "  # model.add(tf.keras.layers.Dropout(drop))\n",
        "  #model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "    \n",
        "  model.add(tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "  # model.add(tf.keras.layers.Dropout(drop))\n",
        "  # model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "  # model.add(tf.keras.layers.Dropout(drop))\n",
        "  # model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "  # model.add(tf.keras.layers.Dropout(drop))\n",
        "  # model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "  # model.add(tf.keras.layers.Dropout(drop))\n",
        "  # model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "\n",
        "  #model.add(tf.keras.layers.Dense(256))\n",
        "  #model.add(tf.keras.layers.Activation('elu'))  \n",
        "  #model.add(tf.keras.layers.BatchNormalization())\n",
        "  #model.add(tf.keras.layers.Dropout(drop))\n",
        "  \n",
        "  model.add(tf.keras.layers.Dense(CLASS_CNT,activation='softmax'))\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "def create_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  drop = 0.5\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=input_data_shape))\n",
        "  model.add(tf.keras.layers.Conv2D(64, (9, 9), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(128, (9, 9), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=input_data_shape))\n",
        "  model.add(tf.keras.layers.Conv2D(96, (7, 7), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(192, (7, 7), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=input_data_shape))\n",
        "  model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=input_data_shape))\n",
        "  model.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "  \n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(1024))\n",
        "  model.add(tf.keras.layers.Activation('elu'))\n",
        "  model.add(tf.keras.layers.Dense(256))\n",
        "  model.add(tf.keras.layers.Activation('elu'))  \n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "  model.add(tf.keras.layers.Dense(CLASS_CNT,activation='softmax'))\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "if strategy != None:\n",
        "  with strategy.scope():\n",
        "    model = create_model_ResNet50()#create_model_vgg19()\n",
        "    model.compile(\n",
        "        #optimizer=tf.keras.optimizers.Adadelta( ),\n",
        "        optimizer=tf.keras.optimizers.SGD(momentum=0.9),\n",
        "         \n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['sparse_categorical_accuracy'])\n",
        "else:\n",
        "    model = create_model_ResNet50()#create_model_vgg19()\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adadelta( ),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['sparse_categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwZJNz0yFLhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "try:\n",
        "  print(\"Loading...\")\n",
        "  model.load_weights('/content/drive/My Drive/resnet50.h5')\n",
        "  print(\"Loading... Ready\")\n",
        "except:\n",
        "  print(\"Unable to load weights...\")\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLjupBIaGgfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(model):\n",
        "  result = model.predict(np.array(test_xy[0]).astype(np.float32))\n",
        "  pos = 0\n",
        "  for i in range(len(result)):\n",
        "    test_y = result[i].argmax()\n",
        "    valid_y = test_xy[1][i]\n",
        "    #print(test_y, valid_y, test_y==valid_y)\n",
        "    pos += (test_y==valid_y)\n",
        "  print(\"validation status :\",pos/len(result))\n",
        "  print(datetime.datetime.now())    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMXquzRVMMBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(n):\n",
        "  num = 0\n",
        "  x = []\n",
        "  y = []\n",
        "  while num < n:\n",
        "    id = random.randint(0,len(dataset[0])-1)\n",
        "    darkness = random.randint(128,255)/255.0\n",
        "    img = cv2.imread(dataset[0][id],cv2.IMREAD_GRAYSCALE)\n",
        "    img = np.expand_dims(img, -1).astype(np.float32)\n",
        "    x.append(img*(1/255.0)*darkness)\n",
        "    y.append(dataset[1][id])\n",
        "    num += 1\n",
        "  return np.array(x),np.array(y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygRwitPNqiES",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "168fc91f-3ea4-4972-f651-db91f8756642"
      },
      "source": [
        "validation_generator = t_generator(400)\n",
        "test_xy = list(zip(*validation_generator))\n",
        "batch_size = 256\n",
        "data_length = ((10000)//batch_size)*batch_size\n",
        "print(\"Data lenght = \", data_length)\n",
        "for i in range(20):\n",
        "  print(\"train ready\")\n",
        "  x,y = get_data(data_length)\n",
        "  print(\"fitting\")\n",
        "  history = model.fit(\n",
        "      x,y,\n",
        "      epochs=100,\n",
        "      batch_size=batch_size\n",
        "  )\n",
        "  validate(model)\n",
        "  model.save_weights('/content/drive/My Drive/resnet50.h5', overwrite=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data lenght =  9984\n",
            "train ready\n",
            "fitting\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_distributed.py:411: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "39/39 [==============================] - 20s 516ms/step - loss: 39.6243 - sparse_categorical_accuracy: 0.0411\n",
            "Epoch 2/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 7.9298 - sparse_categorical_accuracy: 0.0230\n",
            "Epoch 3/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 5.5545 - sparse_categorical_accuracy: 0.0319\n",
            "Epoch 4/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 4.9436 - sparse_categorical_accuracy: 0.0453\n",
            "Epoch 5/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 4.3401 - sparse_categorical_accuracy: 0.0746\n",
            "Epoch 6/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 3.7230 - sparse_categorical_accuracy: 0.1055\n",
            "Epoch 7/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 3.5728 - sparse_categorical_accuracy: 0.1162\n",
            "Epoch 8/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 3.2541 - sparse_categorical_accuracy: 0.1442\n",
            "Epoch 9/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 2.9252 - sparse_categorical_accuracy: 0.1788\n",
            "Epoch 10/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 2.7102 - sparse_categorical_accuracy: 0.2126\n",
            "Epoch 11/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 2.8091 - sparse_categorical_accuracy: 0.1902\n",
            "Epoch 12/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 2.5558 - sparse_categorical_accuracy: 0.2430\n",
            "Epoch 13/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 2.3914 - sparse_categorical_accuracy: 0.2737\n",
            "Epoch 14/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 2.2755 - sparse_categorical_accuracy: 0.2987\n",
            "Epoch 15/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 2.1679 - sparse_categorical_accuracy: 0.3336\n",
            "Epoch 16/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 2.0438 - sparse_categorical_accuracy: 0.3672\n",
            "Epoch 17/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 1.9091 - sparse_categorical_accuracy: 0.4022\n",
            "Epoch 18/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 1.8418 - sparse_categorical_accuracy: 0.4109\n",
            "Epoch 19/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 1.7215 - sparse_categorical_accuracy: 0.4433\n",
            "Epoch 20/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 1.8594 - sparse_categorical_accuracy: 0.4228\n",
            "Epoch 21/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 1.7619 - sparse_categorical_accuracy: 0.4399\n",
            "Epoch 22/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 1.5965 - sparse_categorical_accuracy: 0.4820\n",
            "Epoch 23/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 1.4649 - sparse_categorical_accuracy: 0.5198\n",
            "Epoch 24/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 1.4212 - sparse_categorical_accuracy: 0.5380\n",
            "Epoch 25/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 1.9570 - sparse_categorical_accuracy: 0.3974\n",
            "Epoch 26/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 1.6299 - sparse_categorical_accuracy: 0.4742\n",
            "Epoch 27/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 1.4656 - sparse_categorical_accuracy: 0.5212\n",
            "Epoch 28/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 1.3443 - sparse_categorical_accuracy: 0.5579\n",
            "Epoch 29/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 1.2508 - sparse_categorical_accuracy: 0.5857\n",
            "Epoch 30/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 1.1363 - sparse_categorical_accuracy: 0.6277\n",
            "Epoch 31/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 1.1108 - sparse_categorical_accuracy: 0.6366\n",
            "Epoch 32/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 1.0354 - sparse_categorical_accuracy: 0.6612\n",
            "Epoch 33/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.9153 - sparse_categorical_accuracy: 0.6960\n",
            "Epoch 34/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.8963 - sparse_categorical_accuracy: 0.6975\n",
            "Epoch 35/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.8433 - sparse_categorical_accuracy: 0.7199\n",
            "Epoch 36/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.7256 - sparse_categorical_accuracy: 0.7601\n",
            "Epoch 37/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.6983 - sparse_categorical_accuracy: 0.7675\n",
            "Epoch 38/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.7173 - sparse_categorical_accuracy: 0.7637\n",
            "Epoch 39/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.5875 - sparse_categorical_accuracy: 0.8025\n",
            "Epoch 40/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.5480 - sparse_categorical_accuracy: 0.8175\n",
            "Epoch 41/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.4832 - sparse_categorical_accuracy: 0.8382\n",
            "Epoch 42/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.3850 - sparse_categorical_accuracy: 0.8769\n",
            "Epoch 43/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.3576 - sparse_categorical_accuracy: 0.8787\n",
            "Epoch 44/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.3419 - sparse_categorical_accuracy: 0.8882\n",
            "Epoch 45/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.2989 - sparse_categorical_accuracy: 0.9026\n",
            "Epoch 46/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.2557 - sparse_categorical_accuracy: 0.9195\n",
            "Epoch 47/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.2698 - sparse_categorical_accuracy: 0.9154\n",
            "Epoch 48/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.2622 - sparse_categorical_accuracy: 0.9162\n",
            "Epoch 49/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.1860 - sparse_categorical_accuracy: 0.9435\n",
            "Epoch 50/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.2041 - sparse_categorical_accuracy: 0.9358\n",
            "Epoch 51/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.1862 - sparse_categorical_accuracy: 0.9440\n",
            "Epoch 52/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.1503 - sparse_categorical_accuracy: 0.9525\n",
            "Epoch 53/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.1339 - sparse_categorical_accuracy: 0.9601\n",
            "Epoch 54/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.1259 - sparse_categorical_accuracy: 0.9631\n",
            "Epoch 55/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.1064 - sparse_categorical_accuracy: 0.9699\n",
            "Epoch 56/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0838 - sparse_categorical_accuracy: 0.9763\n",
            "Epoch 57/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0744 - sparse_categorical_accuracy: 0.9808\n",
            "Epoch 58/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0699 - sparse_categorical_accuracy: 0.9812\n",
            "Epoch 59/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0727 - sparse_categorical_accuracy: 0.9801\n",
            "Epoch 60/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0721 - sparse_categorical_accuracy: 0.9816\n",
            "Epoch 61/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0559 - sparse_categorical_accuracy: 0.9871\n",
            "Epoch 62/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0517 - sparse_categorical_accuracy: 0.9861\n",
            "Epoch 63/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0432 - sparse_categorical_accuracy: 0.9887\n",
            "Epoch 64/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0437 - sparse_categorical_accuracy: 0.9883\n",
            "Epoch 65/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0529 - sparse_categorical_accuracy: 0.9845\n",
            "Epoch 66/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0465 - sparse_categorical_accuracy: 0.9879\n",
            "Epoch 67/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0369 - sparse_categorical_accuracy: 0.9913\n",
            "Epoch 68/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0404 - sparse_categorical_accuracy: 0.9894\n",
            "Epoch 69/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0273 - sparse_categorical_accuracy: 0.9939\n",
            "Epoch 70/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0293 - sparse_categorical_accuracy: 0.9930\n",
            "Epoch 71/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0351 - sparse_categorical_accuracy: 0.9908\n",
            "Epoch 72/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0336 - sparse_categorical_accuracy: 0.9917\n",
            "Epoch 73/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0379 - sparse_categorical_accuracy: 0.9914\n",
            "Epoch 74/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0344 - sparse_categorical_accuracy: 0.9910\n",
            "Epoch 75/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0349 - sparse_categorical_accuracy: 0.9919\n",
            "Epoch 76/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0578 - sparse_categorical_accuracy: 0.9829\n",
            "Epoch 77/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0433 - sparse_categorical_accuracy: 0.9887\n",
            "Epoch 78/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0500 - sparse_categorical_accuracy: 0.9857\n",
            "Epoch 79/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0367 - sparse_categorical_accuracy: 0.9908\n",
            "Epoch 80/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0222 - sparse_categorical_accuracy: 0.9951\n",
            "Epoch 81/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0185 - sparse_categorical_accuracy: 0.9961\n",
            "Epoch 82/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0155 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 83/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0170 - sparse_categorical_accuracy: 0.9958\n",
            "Epoch 84/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0226 - sparse_categorical_accuracy: 0.9936\n",
            "Epoch 85/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0217 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 86/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0132 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 87/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0100 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 88/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0145 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 89/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0147 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 90/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0218 - sparse_categorical_accuracy: 0.9946\n",
            "Epoch 91/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0179 - sparse_categorical_accuracy: 0.9962\n",
            "Epoch 92/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0157 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 93/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0137 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 94/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0145 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 95/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 96/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0123 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 97/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 98/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 99/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0155 - sparse_categorical_accuracy: 0.9963\n",
            "Epoch 100/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9981\n",
            "validation status : 0.7425\n",
            "2019-10-01 17:01:14.714719\n",
            "train ready\n",
            "fitting\n",
            "Epoch 1/100\n",
            "39/39 [==============================] - 22s 564ms/step - loss: 0.7591 - sparse_categorical_accuracy: 0.7677\n",
            "Epoch 2/100\n",
            "39/39 [==============================] - 5s 135ms/step - loss: 0.4265 - sparse_categorical_accuracy: 0.8574\n",
            "Epoch 3/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.3555 - sparse_categorical_accuracy: 0.8803\n",
            "Epoch 4/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.2585 - sparse_categorical_accuracy: 0.9123\n",
            "Epoch 5/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.1961 - sparse_categorical_accuracy: 0.9330\n",
            "Epoch 6/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.1650 - sparse_categorical_accuracy: 0.9446\n",
            "Epoch 7/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.1397 - sparse_categorical_accuracy: 0.9538\n",
            "Epoch 8/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.1186 - sparse_categorical_accuracy: 0.9608\n",
            "Epoch 9/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.1087 - sparse_categorical_accuracy: 0.9658\n",
            "Epoch 10/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0937 - sparse_categorical_accuracy: 0.9696\n",
            "Epoch 11/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0637 - sparse_categorical_accuracy: 0.9819\n",
            "Epoch 12/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0781 - sparse_categorical_accuracy: 0.9745\n",
            "Epoch 13/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0813 - sparse_categorical_accuracy: 0.9750\n",
            "Epoch 14/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0764 - sparse_categorical_accuracy: 0.9775\n",
            "Epoch 15/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0501 - sparse_categorical_accuracy: 0.9855\n",
            "Epoch 16/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0307 - sparse_categorical_accuracy: 0.9913\n",
            "Epoch 17/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0302 - sparse_categorical_accuracy: 0.9913\n",
            "Epoch 18/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0338 - sparse_categorical_accuracy: 0.9900\n",
            "Epoch 19/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0313 - sparse_categorical_accuracy: 0.9904\n",
            "Epoch 20/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0345 - sparse_categorical_accuracy: 0.9893\n",
            "Epoch 21/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0268 - sparse_categorical_accuracy: 0.9927\n",
            "Epoch 22/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0202 - sparse_categorical_accuracy: 0.9946\n",
            "Epoch 23/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0221 - sparse_categorical_accuracy: 0.9941\n",
            "Epoch 24/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0286 - sparse_categorical_accuracy: 0.9922\n",
            "Epoch 25/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0191 - sparse_categorical_accuracy: 0.9946\n",
            "Epoch 26/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0178 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 27/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0143 - sparse_categorical_accuracy: 0.9957\n",
            "Epoch 28/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0131 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 29/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0113 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 30/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0150 - sparse_categorical_accuracy: 0.9963\n",
            "Epoch 31/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0152 - sparse_categorical_accuracy: 0.9961\n",
            "Epoch 32/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0149 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 33/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0140 - sparse_categorical_accuracy: 0.9961\n",
            "Epoch 34/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0155 - sparse_categorical_accuracy: 0.9956\n",
            "Epoch 35/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0134 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 36/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0106 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 37/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0160 - sparse_categorical_accuracy: 0.9955\n",
            "Epoch 38/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0195 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 39/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0163 - sparse_categorical_accuracy: 0.9956\n",
            "Epoch 40/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0160 - sparse_categorical_accuracy: 0.9958\n",
            "Epoch 41/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 42/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 43/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0098 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 44/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 45/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 46/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0159 - sparse_categorical_accuracy: 0.9950\n",
            "Epoch 47/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0115 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 48/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 49/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 50/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 51/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 52/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 53/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 54/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0099 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 55/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0158 - sparse_categorical_accuracy: 0.9956\n",
            "Epoch 56/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0100 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 57/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 58/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 59/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 60/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 61/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0103 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 62/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 63/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 64/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 65/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0133 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 66/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0242 - sparse_categorical_accuracy: 0.9933\n",
            "Epoch 67/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0115 - sparse_categorical_accuracy: 0.9964\n",
            "Epoch 68/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 69/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 70/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 71/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0026 - sparse_categorical_accuracy: 0.9997\n",
            "Epoch 72/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0032 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 73/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0032 - sparse_categorical_accuracy: 0.9991\n",
            "Epoch 74/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9990\n",
            "Epoch 75/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 76/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 77/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 78/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 79/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 80/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0028 - sparse_categorical_accuracy: 0.9995\n",
            "Epoch 81/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0033 - sparse_categorical_accuracy: 0.9991\n",
            "Epoch 82/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 83/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 84/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 85/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9997\n",
            "Epoch 86/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9995\n",
            "Epoch 87/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9995\n",
            "Epoch 88/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0118 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 89/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0231 - sparse_categorical_accuracy: 0.9919\n",
            "Epoch 90/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 91/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9992\n",
            "Epoch 92/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0026 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 93/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 94/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9994\n",
            "Epoch 95/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0031 - sparse_categorical_accuracy: 0.9992\n",
            "Epoch 96/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9990\n",
            "Epoch 97/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0032 - sparse_categorical_accuracy: 0.9992\n",
            "Epoch 98/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0029 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 99/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 100/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9996\n",
            "validation status : 0.9275\n",
            "2019-10-01 17:18:49.305075\n",
            "train ready\n",
            "fitting\n",
            "Epoch 1/100\n",
            "39/39 [==============================] - 24s 604ms/step - loss: 0.3399 - sparse_categorical_accuracy: 0.8973\n",
            "Epoch 2/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.2226 - sparse_categorical_accuracy: 0.9252\n",
            "Epoch 3/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.1184 - sparse_categorical_accuracy: 0.9603\n",
            "Epoch 4/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0811 - sparse_categorical_accuracy: 0.9733\n",
            "Epoch 5/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0607 - sparse_categorical_accuracy: 0.9798\n",
            "Epoch 6/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0446 - sparse_categorical_accuracy: 0.9864\n",
            "Epoch 7/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0346 - sparse_categorical_accuracy: 0.9881\n",
            "Epoch 8/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0291 - sparse_categorical_accuracy: 0.9908\n",
            "Epoch 9/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0329 - sparse_categorical_accuracy: 0.9895\n",
            "Epoch 10/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0242 - sparse_categorical_accuracy: 0.9926\n",
            "Epoch 11/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0251 - sparse_categorical_accuracy: 0.9928\n",
            "Epoch 12/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0208 - sparse_categorical_accuracy: 0.9934\n",
            "Epoch 13/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0178 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 14/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0200 - sparse_categorical_accuracy: 0.9946\n",
            "Epoch 15/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0227 - sparse_categorical_accuracy: 0.9935\n",
            "Epoch 16/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0214 - sparse_categorical_accuracy: 0.9930\n",
            "Epoch 17/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0123 - sparse_categorical_accuracy: 0.9961\n",
            "Epoch 18/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0123 - sparse_categorical_accuracy: 0.9958\n",
            "Epoch 19/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0129 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 20/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0117 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 21/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 22/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 23/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 24/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 25/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 26/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0140 - sparse_categorical_accuracy: 0.9959\n",
            "Epoch 27/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0096 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 28/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0111 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 29/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0131 - sparse_categorical_accuracy: 0.9962\n",
            "Epoch 30/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0113 - sparse_categorical_accuracy: 0.9964\n",
            "Epoch 31/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 32/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0102 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 33/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 34/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 35/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 36/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 37/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 38/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 39/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 40/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 41/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0134 - sparse_categorical_accuracy: 0.9963\n",
            "Epoch 42/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0189 - sparse_categorical_accuracy: 0.9950\n",
            "Epoch 43/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0114 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 44/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 45/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0103 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 46/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 47/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 48/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 49/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 50/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 51/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9991\n",
            "Epoch 52/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 53/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9990\n",
            "Epoch 54/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 55/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 56/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 57/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 58/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9997\n",
            "Epoch 59/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9995\n",
            "Epoch 60/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 61/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9997\n",
            "Epoch 62/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9992\n",
            "Epoch 63/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9997\n",
            "Epoch 64/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 65/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9995\n",
            "Epoch 66/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0031 - sparse_categorical_accuracy: 0.9992\n",
            "Epoch 67/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 68/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0029 - sparse_categorical_accuracy: 0.9995\n",
            "Epoch 69/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0030 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 70/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9990\n",
            "Epoch 71/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0030 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 72/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 73/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 74/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 75/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0033 - sparse_categorical_accuracy: 0.9992\n",
            "Epoch 76/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 77/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 78/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0011 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 79/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 9.4902e-04 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 80/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9995\n",
            "Epoch 81/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9995\n",
            "Epoch 82/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 83/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 84/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 85/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 86/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9992\n",
            "Epoch 87/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0029 - sparse_categorical_accuracy: 0.9994\n",
            "Epoch 88/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0033 - sparse_categorical_accuracy: 0.9991\n",
            "Epoch 89/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0029 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 90/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9995\n",
            "Epoch 91/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9995\n",
            "Epoch 92/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 9.4327e-04 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 93/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 94/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0030 - sparse_categorical_accuracy: 0.9990\n",
            "Epoch 95/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 96/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0294 - sparse_categorical_accuracy: 0.9915\n",
            "Epoch 97/100\n",
            "39/39 [==============================] - 5s 138ms/step - loss: 0.0178 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 98/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0097 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 99/100\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 100/100\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9984\n",
            "validation status : 0.96\n",
            "2019-10-01 17:35:28.271915\n",
            "train ready\n",
            "fitting\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}