{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab's New Code Editor",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexEskin/Templates/blob/master/Recognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKO6rlVGp-sk",
        "colab_type": "code",
        "outputId": "9a3a79a8-bc82-4112-f032-ae776a2cf084",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!rm -rf crops_train\n",
        "!rm -rf crops_test\n",
        "!rm -rf maps_resized\n",
        "!rm -rf examples\n",
        "\n",
        "!mkdir maps_resized\n",
        "!mkdir crops_train\n",
        "!mkdir crops_test\n",
        "!mkdir examples\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "WIDTH = 224\n",
        "HEIGHT = 224\n",
        "SOURCE = 'MapsExample'\n",
        "\n",
        "def resizeImages():\n",
        "    path_a = SOURCE\n",
        "    path_b = 'maps_resized'\n",
        "\n",
        "    filenames = []\n",
        "    for r, d, f in os.walk(path_a):\n",
        "        for file in f:\n",
        "            if \".png\" in file:\n",
        "               filenames.append(file)\n",
        "    print(filenames)\n",
        "    images = []\n",
        "    minSizeX = None\n",
        "    minSizeY = None\n",
        "\n",
        "    for filename in filenames:\n",
        "        f_a = os.path.join(path_a, filename)\n",
        "        print(f_a)\n",
        "        im_a = cv2.imread(f_a)\n",
        "        if minSizeX != None:\n",
        "            minSizeX = min(minSizeX,im_a.shape[0])\n",
        "        else:\n",
        "            minSizeX = im_a.shape[0]\n",
        "        if minSizeY != None:\n",
        "            minSizeY = min(minSizeY,im_a.shape[1])          \n",
        "        else:\n",
        "            minSizeY = im_a.shape[1]\n",
        "    print(minSizeX,minSizeY)\n",
        "    for filename in filenames:\n",
        "        f_a = os.path.join(path_a, filename)\n",
        "        f_b = os.path.join(path_b, filename)\n",
        "\n",
        "        im_a = cv2.imread(f_a)\n",
        "        crop_img = im_a[0:minSizeX, 0:minSizeY]\n",
        "        cv2.imwrite(f_b,crop_img)\n",
        "\n",
        "def generateCrops():\n",
        "    path_a = 'maps_resized'\n",
        "    path_b = 'crops_train'\n",
        "    path_c = 'crops_test'\n",
        "    examples = 'examples'\n",
        "    filenames = []\n",
        "    for r, d, f in os.walk(path_a):\n",
        "        for file in f:\n",
        "            filenames.append(file)\n",
        "    counter = 0\n",
        "    for filename in filenames:\n",
        "        f_a = os.path.join(path_a, filename)\n",
        "        im_a = cv2.imread(f_a)\n",
        "        shape = im_a.shape\n",
        "        examples_counter = 0\n",
        "        for i in range(0,shape[0]-WIDTH-1,64):\n",
        "            for j in range(0,shape[1]-HEIGHT-1,64):\n",
        "                path = path_b\n",
        "                if not counter%7:\n",
        "                    path = path_c       \n",
        "                submap = os.path.join(path, filename)\n",
        "                try:\n",
        "                  os.mkdir(submap)\n",
        "                except:\n",
        "                  pass\n",
        "                submap = os.path.join(submap,str(counter)+\".png\")\n",
        "                submap_image = im_a[i:i+HEIGHT,j:j+WIDTH]\n",
        "                cv2.imwrite(submap,submap_image)\n",
        "                if examples_counter < 32:\n",
        "                    expath = os.path.join(examples, filename)\n",
        "                    try:\n",
        "                        if not examples_counter:\n",
        "                            os.mkdir(expath)\n",
        "                    except Exception as e:\n",
        "                        pass\n",
        "                    exmap = os.path.join(expath,str(counter)+\".png\")\n",
        "                    cv2.imwrite(exmap,submap_image)\n",
        "                    examples_counter = examples_counter + 1\n",
        "                counter += 1\n",
        "\n",
        "\"\"\"Download maps\"\"\"\n",
        "\n",
        "!rm -rf MapsExample\n",
        "\n",
        "!git clone https://github.com/AlexEskin/MapsExample.git\n",
        "\n",
        "!ls MapsExample\n",
        "\n",
        "resizeImages()\n",
        "generateCrops()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MapsExample'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/55)\u001b[K\rremote: Counting objects:   3% (2/55)\u001b[K\rremote: Counting objects:   5% (3/55)\u001b[K\rremote: Counting objects:   7% (4/55)\u001b[K\rremote: Counting objects:   9% (5/55)\u001b[K\rremote: Counting objects:  10% (6/55)\u001b[K\rremote: Counting objects:  12% (7/55)\u001b[K\rremote: Counting objects:  14% (8/55)\u001b[K\rremote: Counting objects:  16% (9/55)\u001b[K\rremote: Counting objects:  18% (10/55)\u001b[K\rremote: Counting objects:  20% (11/55)\u001b[K\rremote: Counting objects:  21% (12/55)\u001b[K\rremote: Counting objects:  23% (13/55)\u001b[K\rremote: Counting objects:  25% (14/55)\u001b[K\rremote: Counting objects:  27% (15/55)\u001b[K\rremote: Counting objects:  29% (16/55)\u001b[K\rremote: Counting objects:  30% (17/55)\u001b[K\rremote: Counting objects:  32% (18/55)\u001b[K\rremote: Counting objects:  34% (19/55)\u001b[K\rremote: Counting objects:  36% (20/55)\u001b[K\rremote: Counting objects:  38% (21/55)\u001b[K\rremote: Counting objects:  40% (22/55)\u001b[K\rremote: Counting objects:  41% (23/55)\u001b[K\rremote: Counting objects:  43% (24/55)\u001b[K\rremote: Counting objects:  45% (25/55)\u001b[K\rremote: Counting objects:  47% (26/55)\u001b[K\rremote: Counting objects:  49% (27/55)\u001b[K\rremote: Counting objects:  50% (28/55)\u001b[K\rremote: Counting objects:  52% (29/55)\u001b[K\rremote: Counting objects:  54% (30/55)\u001b[K\rremote: Counting objects:  56% (31/55)\u001b[K\rremote: Counting objects:  58% (32/55)\u001b[K\rremote: Counting objects:  60% (33/55)\u001b[K\rremote: Counting objects:  61% (34/55)\u001b[K\rremote: Counting objects:  63% (35/55)\u001b[K\rremote: Counting objects:  65% (36/55)\u001b[K\rremote: Counting objects:  67% (37/55)\u001b[K\rremote: Counting objects:  69% (38/55)\u001b[K\rremote: Counting objects:  70% (39/55)\u001b[K\rremote: Counting objects:  72% (40/55)\u001b[K\rremote: Counting objects:  74% (41/55)\u001b[K\rremote: Counting objects:  76% (42/55)\u001b[K\rremote: Counting objects:  78% (43/55)\u001b[K\rremote: Counting objects:  80% (44/55)\u001b[K\rremote: Counting objects:  81% (45/55)\u001b[K\rremote: Counting objects:  83% (46/55)\u001b[K\rremote: Counting objects:  85% (47/55)\u001b[K\rremote: Counting objects:  87% (48/55)\u001b[K\rremote: Counting objects:  89% (49/55)\u001b[K\rremote: Counting objects:  90% (50/55)\u001b[K\rremote: Counting objects:  92% (51/55)\u001b[K\rremote: Counting objects:  94% (52/55)\u001b[K\rremote: Counting objects:  96% (53/55)\u001b[K\rremote: Counting objects:  98% (54/55)\u001b[K\rremote: Counting objects: 100% (55/55)\u001b[K\rremote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 55 (delta 0), reused 55 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (55/55), done.\n",
            "map_10.png  map_19.png\tmap_27.png  map_35.png\tmap_43.png  map_5.png\n",
            "map_11.png  map_1.png\tmap_28.png  map_36.png\tmap_44.png  map_6.png\n",
            "map_12.png  map_20.png\tmap_29.png  map_37.png\tmap_45.png  map_7.png\n",
            "map_13.png  map_21.png\tmap_2.png   map_38.png\tmap_46.png  map_8.png\n",
            "map_14.png  map_22.png\tmap_30.png  map_39.png\tmap_47.png  map_9.png\n",
            "map_15.png  map_23.png\tmap_31.png  map_3.png\tmap_48.png  README.md\n",
            "map_16.png  map_24.png\tmap_32.png  map_40.png\tmap_49.png\n",
            "map_17.png  map_25.png\tmap_33.png  map_41.png\tmap_4.png\n",
            "map_18.png  map_26.png\tmap_34.png  map_42.png\tmap_50.png\n",
            "['map_50.png', 'map_31.png', 'map_29.png', 'map_23.png', 'map_12.png', 'map_14.png', 'map_1.png', 'map_21.png', 'map_34.png', 'map_2.png', 'map_42.png', 'map_17.png', 'map_4.png', 'map_7.png', 'map_37.png', 'map_24.png', 'map_18.png', 'map_45.png', 'map_16.png', 'map_11.png', 'map_30.png', 'map_10.png', 'map_48.png', 'map_44.png', 'map_39.png', 'map_36.png', 'map_22.png', 'map_13.png', 'map_40.png', 'map_3.png', 'map_28.png', 'map_5.png', 'map_19.png', 'map_25.png', 'map_38.png', 'map_20.png', 'map_49.png', 'map_33.png', 'map_8.png', 'map_46.png', 'map_6.png', 'map_32.png', 'map_41.png', 'map_26.png', 'map_43.png', 'map_35.png', 'map_9.png', 'map_47.png', 'map_27.png', 'map_15.png']\n",
            "MapsExample/map_50.png\n",
            "MapsExample/map_31.png\n",
            "MapsExample/map_29.png\n",
            "MapsExample/map_23.png\n",
            "MapsExample/map_12.png\n",
            "MapsExample/map_14.png\n",
            "MapsExample/map_1.png\n",
            "MapsExample/map_21.png\n",
            "MapsExample/map_34.png\n",
            "MapsExample/map_2.png\n",
            "MapsExample/map_42.png\n",
            "MapsExample/map_17.png\n",
            "MapsExample/map_4.png\n",
            "MapsExample/map_7.png\n",
            "MapsExample/map_37.png\n",
            "MapsExample/map_24.png\n",
            "MapsExample/map_18.png\n",
            "MapsExample/map_45.png\n",
            "MapsExample/map_16.png\n",
            "MapsExample/map_11.png\n",
            "MapsExample/map_30.png\n",
            "MapsExample/map_10.png\n",
            "MapsExample/map_48.png\n",
            "MapsExample/map_44.png\n",
            "MapsExample/map_39.png\n",
            "MapsExample/map_36.png\n",
            "MapsExample/map_22.png\n",
            "MapsExample/map_13.png\n",
            "MapsExample/map_40.png\n",
            "MapsExample/map_3.png\n",
            "MapsExample/map_28.png\n",
            "MapsExample/map_5.png\n",
            "MapsExample/map_19.png\n",
            "MapsExample/map_25.png\n",
            "MapsExample/map_38.png\n",
            "MapsExample/map_20.png\n",
            "MapsExample/map_49.png\n",
            "MapsExample/map_33.png\n",
            "MapsExample/map_8.png\n",
            "MapsExample/map_46.png\n",
            "MapsExample/map_6.png\n",
            "MapsExample/map_32.png\n",
            "MapsExample/map_41.png\n",
            "MapsExample/map_26.png\n",
            "MapsExample/map_43.png\n",
            "MapsExample/map_35.png\n",
            "MapsExample/map_9.png\n",
            "MapsExample/map_47.png\n",
            "MapsExample/map_27.png\n",
            "MapsExample/map_15.png\n",
            "831 1461\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYaTQOzkqJyE",
        "colab_type": "code",
        "outputId": "7c8764ab-244d-4336-d5a5-5ef1f653fb5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import datetime\n",
        "import distutils\n",
        "if distutils.version.LooseVersion(tf.__version__) < '1.14':\n",
        "    raise Exception('This notebook is compatible with TensorFlow 1.14 or higher, for TensorFlow 1.13 or lower please use the previous version at https://github.com/tensorflow/tpu/blob/r1.13/tools/colab/fashion_mnist.ipynb')\n",
        "\n",
        "import pathlib\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "CLASS_CNT = None\n",
        "\n",
        "def generate_dataset(dir):\n",
        "  global CLASS_CNT\n",
        "  data_root = pathlib.Path(dir)\n",
        "  label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
        "  if CLASS_CNT == None:\n",
        "    CLASS_CNT = len(label_names)\n",
        "    \n",
        "  all_image_paths = list(data_root.glob('*/*'))\n",
        "  all_image_paths = [str(path) for path in all_image_paths]\n",
        "  random.shuffle(all_image_paths)\n",
        "\n",
        "  label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
        "  label_to_index = dict((name, index) for index,name in enumerate(label_names))\n",
        "\n",
        "  all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
        "                      for path in all_image_paths]\n",
        "  print(\"First 10 labels indices: \", all_image_labels[:10])\n",
        "\n",
        "  return (all_image_paths,all_image_labels)\n",
        "\n",
        "dataset = generate_dataset(\"crops_train\")\n",
        "test_dataset = generate_dataset(\"crops_test\")\n",
        "\n",
        "def tr_generator(n):\n",
        "  num = 0\n",
        "  while num < n:\n",
        "    id = random.randint(0,len(dataset[0])-1)\n",
        "    img = cv2.imread(dataset[0][id],cv2.IMREAD_GRAYSCALE)\n",
        "    img = np.expand_dims(img, -1).astype(np.float32)\n",
        "    yield img*(1/255.0), dataset[1][id]\n",
        "    num += 1\n",
        "    \n",
        "    \n",
        "def t_generator(n):\n",
        "  num = 0\n",
        "  while num < n:\n",
        "    id = random.randint(0,len(test_dataset[0])-1)\n",
        "    img = cv2.imread(test_dataset[0][id],cv2.IMREAD_GRAYSCALE)\n",
        "    img = np.expand_dims(img, -1).astype(np.float32)\n",
        "    yield img*(1/255.0), test_dataset[1][id]\n",
        "    num += 1\n",
        "    \n",
        "\n",
        "input_data = dataset[0][0]\n",
        "input_data = cv2.imread(input_data,cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
        "input_data = np.expand_dims(input_data, -1)\n",
        "input_data_shape = input_data.shape\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 10 labels indices:  [30, 41, 10, 36, 3, 26, 35, 25, 38, 1]\n",
            "First 10 labels indices:  [3, 49, 39, 46, 48, 14, 11, 47, 47, 22]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfzlfqTOqehC",
        "colab_type": "code",
        "outputId": "8ea40c6c-fc86-494d-f35d-f7f10a924fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "\n",
        "strategy = None\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  resolver = tf.contrib.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "  tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "  strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
        "\n",
        "def create_model_vgg19():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  drop = 0.3\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=input_data_shape))\n",
        "  model.add(tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "    \n",
        "  model.add(tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  \n",
        "\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(2048))\n",
        "  model.add(tf.keras.layers.Activation('elu'))\n",
        "  #model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(1024))\n",
        "  model.add(tf.keras.layers.Activation('elu'))\n",
        "  #model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "\n",
        "  #model.add(tf.keras.layers.Dense(256))\n",
        "  #model.add(tf.keras.layers.Activation('elu'))  \n",
        "  #model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "  \n",
        "  model.add(tf.keras.layers.Dense(CLASS_CNT))\n",
        "  model.add(tf.keras.layers.Activation('softmax'))\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "def create_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  drop = 0.2\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=input_data_shape))\n",
        "  model.add(tf.keras.layers.Conv2D(64, (9, 9), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(128, (9, 9), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=input_data_shape))\n",
        "  model.add(tf.keras.layers.Conv2D(96, (7, 7), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(192, (7, 7), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=input_data_shape))\n",
        "  model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=input_data_shape))\n",
        "  model.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "  \n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(1024))\n",
        "  model.add(tf.keras.layers.Activation('elu'))\n",
        "  model.add(tf.keras.layers.Dense(256))\n",
        "  model.add(tf.keras.layers.Activation('elu'))  \n",
        "  model.add(tf.keras.layers.Dropout(drop))\n",
        "  model.add(tf.keras.layers.Dense(CLASS_CNT))\n",
        "  model.add(tf.keras.layers.Activation('softmax'))\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "if strategy != None:\n",
        "  with strategy.scope():\n",
        "    model = create_model_vgg19()\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adadelta( ),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['sparse_categorical_accuracy'])\n",
        "else:\n",
        "    model = create_model_vgg19()\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adadelta( ),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['sparse_categorical_accuracy'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Initializing the TPU system.\n",
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.46.87.18:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 12031864767707300793)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 12463054145494924263)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 6103222464848982332)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 8242181672009685281)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 11058254443163193041)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4407318975204530743)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 6422749599294957353)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 14732921416362544838)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 5925174392006291873)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 1229709717090618678)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 5455238871126517454)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 224, 224, 1)       4         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 224, 224, 64)      640       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 224, 224, 64)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 224, 224, 64)      256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 112, 112, 128)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 112, 112, 128)     512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 56, 56, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 56, 56, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 28, 28, 512)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 28, 28, 512)       2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 100352)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2048)              205522944 \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                51250     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 50)                0         \n",
            "=================================================================\n",
            "Total params: 218,260,214\n",
            "Trainable params: 218,258,292\n",
            "Non-trainable params: 1,922\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygRwitPNqiES",
        "colab_type": "code",
        "outputId": "bc1f96d9-b540-418c-ebb2-6a66bd4e8a72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "try:\n",
        "  model.load_weights('/content/drive/My Drive/vgg19.h5')\n",
        "except:\n",
        "  print(\"Unable to load weights...\")\n",
        "  pass\n",
        "\n",
        "while True:\n",
        "  training_generator = tr_generator(1040*4)\n",
        "  #\n",
        "  # validation_generator = t_generator(200)\n",
        "  model.save_weights('/content/drive/My Drive/vgg19.h5', overwrite=True)\n",
        "  train_xy =list(zip(*training_generator))\n",
        "  print(\"train ready\")\n",
        "  # test_xy = list(zip(*validation_generator))\n",
        "  # print(\"validation ready\")\n",
        "  train_xy = (np.array(train_xy[0]).astype(np.float32),np.array(train_xy[1]).astype(np.float32))\n",
        "  # test_xy = (np.array(test_xy[0]).astype(np.float32),np.array(test_xy[1]).astype(np.float32))\n",
        "  print(\"fitting\")\n",
        "  history = model.fit(\n",
        "      train_xy[0],train_xy[1],\n",
        "      epochs=75,\n",
        "      steps_per_epoch=13*4\n",
        "  )\n",
        "  \n",
        "  print(datetime.datetime.now())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Unable to load weights...\n",
            "train ready\n",
            "fitting\n",
            "Epoch 1/75\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_distributed.py:411: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "52/52 [==============================] - 27s 510ms/step - loss: 5.3750 - sparse_categorical_accuracy: 0.0404\n",
            "Epoch 2/75\n",
            "52/52 [==============================] - 12s 224ms/step - loss: 4.3409 - sparse_categorical_accuracy: 0.0750\n",
            "Epoch 3/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 3.9562 - sparse_categorical_accuracy: 0.0962\n",
            "Epoch 4/75\n",
            "52/52 [==============================] - 12s 224ms/step - loss: 3.7389 - sparse_categorical_accuracy: 0.1050\n",
            "Epoch 5/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 3.5787 - sparse_categorical_accuracy: 0.1161\n",
            "Epoch 6/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 3.4485 - sparse_categorical_accuracy: 0.1430\n",
            "Epoch 7/75\n",
            "52/52 [==============================] - 12s 224ms/step - loss: 3.3058 - sparse_categorical_accuracy: 0.1495\n",
            "Epoch 8/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 3.2804 - sparse_categorical_accuracy: 0.1555\n",
            "Epoch 9/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 3.1790 - sparse_categorical_accuracy: 0.1707\n",
            "Epoch 10/75\n",
            "52/52 [==============================] - 12s 224ms/step - loss: 3.0909 - sparse_categorical_accuracy: 0.1885\n",
            "Epoch 11/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 3.0294 - sparse_categorical_accuracy: 0.1887\n",
            "Epoch 12/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 3.0146 - sparse_categorical_accuracy: 0.1995\n",
            "Epoch 13/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 2.9388 - sparse_categorical_accuracy: 0.2079\n",
            "Epoch 14/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 2.8411 - sparse_categorical_accuracy: 0.2224\n",
            "Epoch 15/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 2.7931 - sparse_categorical_accuracy: 0.2428\n",
            "Epoch 16/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 2.7567 - sparse_categorical_accuracy: 0.2430\n",
            "Epoch 17/75\n",
            "52/52 [==============================] - 12s 224ms/step - loss: 2.6812 - sparse_categorical_accuracy: 0.2553\n",
            "Epoch 18/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 2.6575 - sparse_categorical_accuracy: 0.2635\n",
            "Epoch 19/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 2.5603 - sparse_categorical_accuracy: 0.2827\n",
            "Epoch 20/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 2.5577 - sparse_categorical_accuracy: 0.2887\n",
            "Epoch 21/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 2.4891 - sparse_categorical_accuracy: 0.2885\n",
            "Epoch 22/75\n",
            "52/52 [==============================] - 12s 224ms/step - loss: 2.4108 - sparse_categorical_accuracy: 0.3173\n",
            "Epoch 23/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 2.4269 - sparse_categorical_accuracy: 0.3101\n",
            "Epoch 24/75\n",
            "52/52 [==============================] - 12s 224ms/step - loss: 2.3059 - sparse_categorical_accuracy: 0.3363\n",
            "Epoch 25/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 2.2164 - sparse_categorical_accuracy: 0.3651\n",
            "Epoch 26/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 2.1829 - sparse_categorical_accuracy: 0.3553\n",
            "Epoch 27/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 2.2052 - sparse_categorical_accuracy: 0.3620\n",
            "Epoch 28/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 2.1059 - sparse_categorical_accuracy: 0.3861\n",
            "Epoch 29/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 2.1181 - sparse_categorical_accuracy: 0.3885\n",
            "Epoch 30/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 2.0852 - sparse_categorical_accuracy: 0.3885\n",
            "Epoch 31/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.9975 - sparse_categorical_accuracy: 0.4089\n",
            "Epoch 32/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 2.0113 - sparse_categorical_accuracy: 0.4031\n",
            "Epoch 33/75\n",
            "52/52 [==============================] - 12s 224ms/step - loss: 1.9559 - sparse_categorical_accuracy: 0.4139\n",
            "Epoch 34/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.9608 - sparse_categorical_accuracy: 0.4190\n",
            "Epoch 35/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.8614 - sparse_categorical_accuracy: 0.4397\n",
            "Epoch 36/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.8938 - sparse_categorical_accuracy: 0.4322\n",
            "Epoch 37/75\n",
            "52/52 [==============================] - 12s 224ms/step - loss: 1.8547 - sparse_categorical_accuracy: 0.4560\n",
            "Epoch 38/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.7856 - sparse_categorical_accuracy: 0.4620\n",
            "Epoch 39/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.7851 - sparse_categorical_accuracy: 0.4565\n",
            "Epoch 40/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.7258 - sparse_categorical_accuracy: 0.4719\n",
            "Epoch 41/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.6879 - sparse_categorical_accuracy: 0.4870\n",
            "Epoch 42/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 1.6831 - sparse_categorical_accuracy: 0.4935\n",
            "Epoch 43/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.6345 - sparse_categorical_accuracy: 0.5038\n",
            "Epoch 44/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.6203 - sparse_categorical_accuracy: 0.5094\n",
            "Epoch 45/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.6311 - sparse_categorical_accuracy: 0.5048\n",
            "Epoch 46/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.5626 - sparse_categorical_accuracy: 0.5200\n",
            "Epoch 47/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.5519 - sparse_categorical_accuracy: 0.5248\n",
            "Epoch 48/75\n",
            "52/52 [==============================] - 12s 224ms/step - loss: 1.5114 - sparse_categorical_accuracy: 0.5312\n",
            "Epoch 49/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.5057 - sparse_categorical_accuracy: 0.5322\n",
            "Epoch 50/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.4478 - sparse_categorical_accuracy: 0.5529\n",
            "Epoch 51/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.4298 - sparse_categorical_accuracy: 0.5560\n",
            "Epoch 52/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.4357 - sparse_categorical_accuracy: 0.5550\n",
            "Epoch 53/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.4206 - sparse_categorical_accuracy: 0.5517\n",
            "Epoch 54/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 1.3830 - sparse_categorical_accuracy: 0.5791\n",
            "Epoch 55/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.2906 - sparse_categorical_accuracy: 0.5933\n",
            "Epoch 56/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.3706 - sparse_categorical_accuracy: 0.5762\n",
            "Epoch 57/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.3376 - sparse_categorical_accuracy: 0.5875\n",
            "Epoch 58/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 1.2918 - sparse_categorical_accuracy: 0.6022\n",
            "Epoch 59/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.2921 - sparse_categorical_accuracy: 0.5964\n",
            "Epoch 60/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.2548 - sparse_categorical_accuracy: 0.6099\n",
            "Epoch 61/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.1955 - sparse_categorical_accuracy: 0.6264\n",
            "Epoch 62/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.1608 - sparse_categorical_accuracy: 0.6346\n",
            "Epoch 63/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.1703 - sparse_categorical_accuracy: 0.6346\n",
            "Epoch 64/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.1711 - sparse_categorical_accuracy: 0.6411\n",
            "Epoch 65/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.1900 - sparse_categorical_accuracy: 0.6264\n",
            "Epoch 66/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.1893 - sparse_categorical_accuracy: 0.6293\n",
            "Epoch 67/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 1.1029 - sparse_categorical_accuracy: 0.6567\n",
            "Epoch 68/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 1.0495 - sparse_categorical_accuracy: 0.6656\n",
            "Epoch 69/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.0534 - sparse_categorical_accuracy: 0.6661\n",
            "Epoch 70/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.0446 - sparse_categorical_accuracy: 0.6654\n",
            "Epoch 71/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.0521 - sparse_categorical_accuracy: 0.6752\n",
            "Epoch 72/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 1.0152 - sparse_categorical_accuracy: 0.6776\n",
            "Epoch 73/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.9824 - sparse_categorical_accuracy: 0.6899\n",
            "Epoch 74/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.9884 - sparse_categorical_accuracy: 0.6935\n",
            "Epoch 75/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.9799 - sparse_categorical_accuracy: 0.6942\n",
            "2019-09-30 11:59:28.411304\n",
            "train ready\n",
            "fitting\n",
            "Epoch 1/75\n",
            "52/52 [==============================] - 27s 525ms/step - loss: 1.8024 - sparse_categorical_accuracy: 0.4858\n",
            "Epoch 2/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.7018 - sparse_categorical_accuracy: 0.5053\n",
            "Epoch 3/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.6506 - sparse_categorical_accuracy: 0.5166\n",
            "Epoch 4/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.6014 - sparse_categorical_accuracy: 0.5303\n",
            "Epoch 5/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.5919 - sparse_categorical_accuracy: 0.5159\n",
            "Epoch 6/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.5280 - sparse_categorical_accuracy: 0.5392\n",
            "Epoch 7/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.5224 - sparse_categorical_accuracy: 0.5418\n",
            "Epoch 8/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.4891 - sparse_categorical_accuracy: 0.5483\n",
            "Epoch 9/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.4067 - sparse_categorical_accuracy: 0.5630\n",
            "Epoch 10/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.3937 - sparse_categorical_accuracy: 0.5731\n",
            "Epoch 11/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 1.3740 - sparse_categorical_accuracy: 0.5798\n",
            "Epoch 12/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 1.3756 - sparse_categorical_accuracy: 0.5748\n",
            "Epoch 13/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.3688 - sparse_categorical_accuracy: 0.5760\n",
            "Epoch 14/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.2803 - sparse_categorical_accuracy: 0.6050\n",
            "Epoch 15/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.2611 - sparse_categorical_accuracy: 0.6062\n",
            "Epoch 16/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 1.2282 - sparse_categorical_accuracy: 0.6166\n",
            "Epoch 17/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 1.2243 - sparse_categorical_accuracy: 0.6202\n",
            "Epoch 18/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.1438 - sparse_categorical_accuracy: 0.6298\n",
            "Epoch 19/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 1.1720 - sparse_categorical_accuracy: 0.6344\n",
            "Epoch 20/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 1.1561 - sparse_categorical_accuracy: 0.6397\n",
            "Epoch 21/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 1.1619 - sparse_categorical_accuracy: 0.6418\n",
            "Epoch 22/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 1.1044 - sparse_categorical_accuracy: 0.6471\n",
            "Epoch 23/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.1025 - sparse_categorical_accuracy: 0.6582\n",
            "Epoch 24/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.0733 - sparse_categorical_accuracy: 0.6572\n",
            "Epoch 25/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 1.0419 - sparse_categorical_accuracy: 0.6714\n",
            "Epoch 26/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 1.0798 - sparse_categorical_accuracy: 0.6613\n",
            "Epoch 27/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 1.0105 - sparse_categorical_accuracy: 0.6769\n",
            "Epoch 28/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.9964 - sparse_categorical_accuracy: 0.6817\n",
            "Epoch 29/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.9705 - sparse_categorical_accuracy: 0.6925\n",
            "Epoch 30/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.9169 - sparse_categorical_accuracy: 0.7002\n",
            "Epoch 31/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.9525 - sparse_categorical_accuracy: 0.6911\n",
            "Epoch 32/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.9175 - sparse_categorical_accuracy: 0.7063\n",
            "Epoch 33/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.8652 - sparse_categorical_accuracy: 0.7180\n",
            "Epoch 34/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.8610 - sparse_categorical_accuracy: 0.7245\n",
            "Epoch 35/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.8668 - sparse_categorical_accuracy: 0.7204\n",
            "Epoch 36/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.8221 - sparse_categorical_accuracy: 0.7353\n",
            "Epoch 37/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.8326 - sparse_categorical_accuracy: 0.7332\n",
            "Epoch 38/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.8230 - sparse_categorical_accuracy: 0.7387\n",
            "Epoch 39/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.7570 - sparse_categorical_accuracy: 0.7654\n",
            "Epoch 40/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.8160 - sparse_categorical_accuracy: 0.7370\n",
            "Epoch 41/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.7667 - sparse_categorical_accuracy: 0.7611\n",
            "Epoch 42/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.7526 - sparse_categorical_accuracy: 0.7560\n",
            "Epoch 43/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.7106 - sparse_categorical_accuracy: 0.7714\n",
            "Epoch 44/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.7244 - sparse_categorical_accuracy: 0.7613\n",
            "Epoch 45/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.7103 - sparse_categorical_accuracy: 0.7724\n",
            "Epoch 46/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.7111 - sparse_categorical_accuracy: 0.7769\n",
            "Epoch 47/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.6823 - sparse_categorical_accuracy: 0.7767\n",
            "Epoch 48/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.6875 - sparse_categorical_accuracy: 0.7825\n",
            "Epoch 49/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.6725 - sparse_categorical_accuracy: 0.7827\n",
            "Epoch 50/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.6480 - sparse_categorical_accuracy: 0.7875\n",
            "Epoch 51/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.6253 - sparse_categorical_accuracy: 0.8050\n",
            "Epoch 52/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.6477 - sparse_categorical_accuracy: 0.7925\n",
            "Epoch 53/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.6071 - sparse_categorical_accuracy: 0.8002\n",
            "Epoch 54/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.6531 - sparse_categorical_accuracy: 0.7918\n",
            "Epoch 55/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.6097 - sparse_categorical_accuracy: 0.8031\n",
            "Epoch 56/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.6017 - sparse_categorical_accuracy: 0.8067\n",
            "Epoch 57/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.5881 - sparse_categorical_accuracy: 0.8089\n",
            "Epoch 58/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.5589 - sparse_categorical_accuracy: 0.8224\n",
            "Epoch 59/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.6003 - sparse_categorical_accuracy: 0.8024\n",
            "Epoch 60/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.5790 - sparse_categorical_accuracy: 0.8147\n",
            "Epoch 61/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.5316 - sparse_categorical_accuracy: 0.8327\n",
            "Epoch 62/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.5529 - sparse_categorical_accuracy: 0.8197\n",
            "Epoch 63/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.5244 - sparse_categorical_accuracy: 0.8276\n",
            "Epoch 64/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.5224 - sparse_categorical_accuracy: 0.8279\n",
            "Epoch 65/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.5049 - sparse_categorical_accuracy: 0.8334\n",
            "Epoch 66/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.5149 - sparse_categorical_accuracy: 0.8344\n",
            "Epoch 67/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.4921 - sparse_categorical_accuracy: 0.8466\n",
            "Epoch 68/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.4924 - sparse_categorical_accuracy: 0.8387\n",
            "Epoch 69/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.4765 - sparse_categorical_accuracy: 0.8469\n",
            "Epoch 70/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.4946 - sparse_categorical_accuracy: 0.8358\n",
            "Epoch 71/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.4368 - sparse_categorical_accuracy: 0.8577\n",
            "Epoch 72/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.4618 - sparse_categorical_accuracy: 0.8495\n",
            "Epoch 73/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.4694 - sparse_categorical_accuracy: 0.8452\n",
            "Epoch 74/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.4492 - sparse_categorical_accuracy: 0.8495\n",
            "Epoch 75/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.4302 - sparse_categorical_accuracy: 0.8555\n",
            "2019-09-30 12:15:15.895103\n",
            "train ready\n",
            "fitting\n",
            "Epoch 1/75\n",
            "52/52 [==============================] - 27s 518ms/step - loss: 1.1326 - sparse_categorical_accuracy: 0.6685\n",
            "Epoch 2/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 1.0185 - sparse_categorical_accuracy: 0.6906\n",
            "Epoch 3/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.9816 - sparse_categorical_accuracy: 0.6986\n",
            "Epoch 4/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.9393 - sparse_categorical_accuracy: 0.7053\n",
            "Epoch 5/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.9321 - sparse_categorical_accuracy: 0.7175\n",
            "Epoch 6/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.8777 - sparse_categorical_accuracy: 0.7262\n",
            "Epoch 7/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.8593 - sparse_categorical_accuracy: 0.7269\n",
            "Epoch 8/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.8567 - sparse_categorical_accuracy: 0.7300\n",
            "Epoch 9/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.7925 - sparse_categorical_accuracy: 0.7445\n",
            "Epoch 10/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.8156 - sparse_categorical_accuracy: 0.7394\n",
            "Epoch 11/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.8087 - sparse_categorical_accuracy: 0.7442\n",
            "Epoch 12/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.7874 - sparse_categorical_accuracy: 0.7466\n",
            "Epoch 13/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.7609 - sparse_categorical_accuracy: 0.7577\n",
            "Epoch 14/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.7044 - sparse_categorical_accuracy: 0.7743\n",
            "Epoch 15/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.7271 - sparse_categorical_accuracy: 0.7632\n",
            "Epoch 16/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.6975 - sparse_categorical_accuracy: 0.7760\n",
            "Epoch 17/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.6650 - sparse_categorical_accuracy: 0.7875\n",
            "Epoch 18/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.6548 - sparse_categorical_accuracy: 0.7815\n",
            "Epoch 19/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.6415 - sparse_categorical_accuracy: 0.7899\n",
            "Epoch 20/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.6343 - sparse_categorical_accuracy: 0.7930\n",
            "Epoch 21/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.5910 - sparse_categorical_accuracy: 0.8050\n",
            "Epoch 22/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.6121 - sparse_categorical_accuracy: 0.8089\n",
            "Epoch 23/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.5987 - sparse_categorical_accuracy: 0.8031\n",
            "Epoch 24/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.5574 - sparse_categorical_accuracy: 0.8214\n",
            "Epoch 25/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.5872 - sparse_categorical_accuracy: 0.8034\n",
            "Epoch 26/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.5671 - sparse_categorical_accuracy: 0.8144\n",
            "Epoch 27/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.5541 - sparse_categorical_accuracy: 0.8137\n",
            "Epoch 28/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.5430 - sparse_categorical_accuracy: 0.8238\n",
            "Epoch 29/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.5105 - sparse_categorical_accuracy: 0.8349\n",
            "Epoch 30/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.4980 - sparse_categorical_accuracy: 0.8325\n",
            "Epoch 31/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.4940 - sparse_categorical_accuracy: 0.8365\n",
            "Epoch 32/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.4702 - sparse_categorical_accuracy: 0.8406\n",
            "Epoch 33/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.5067 - sparse_categorical_accuracy: 0.8356\n",
            "Epoch 34/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.4555 - sparse_categorical_accuracy: 0.8486\n",
            "Epoch 35/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.4727 - sparse_categorical_accuracy: 0.8440\n",
            "Epoch 36/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.4916 - sparse_categorical_accuracy: 0.8344\n",
            "Epoch 37/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.4382 - sparse_categorical_accuracy: 0.8577\n",
            "Epoch 38/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.4443 - sparse_categorical_accuracy: 0.8550\n",
            "Epoch 39/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.4317 - sparse_categorical_accuracy: 0.8606\n",
            "Epoch 40/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.4062 - sparse_categorical_accuracy: 0.8678\n",
            "Epoch 41/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.4321 - sparse_categorical_accuracy: 0.8584\n",
            "Epoch 42/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.4567 - sparse_categorical_accuracy: 0.8522\n",
            "Epoch 43/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.4298 - sparse_categorical_accuracy: 0.8608\n",
            "Epoch 44/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.3972 - sparse_categorical_accuracy: 0.8673\n",
            "Epoch 45/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3827 - sparse_categorical_accuracy: 0.8793\n",
            "Epoch 46/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3770 - sparse_categorical_accuracy: 0.8808\n",
            "Epoch 47/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3501 - sparse_categorical_accuracy: 0.8849\n",
            "Epoch 48/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.4031 - sparse_categorical_accuracy: 0.8719\n",
            "Epoch 49/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3606 - sparse_categorical_accuracy: 0.8798\n",
            "Epoch 50/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3794 - sparse_categorical_accuracy: 0.8808\n",
            "Epoch 51/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3210 - sparse_categorical_accuracy: 0.8957\n",
            "Epoch 52/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3455 - sparse_categorical_accuracy: 0.8875\n",
            "Epoch 53/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3544 - sparse_categorical_accuracy: 0.8861\n",
            "Epoch 54/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3596 - sparse_categorical_accuracy: 0.8832\n",
            "Epoch 55/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3330 - sparse_categorical_accuracy: 0.8935\n",
            "Epoch 56/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3445 - sparse_categorical_accuracy: 0.8921\n",
            "Epoch 57/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.3614 - sparse_categorical_accuracy: 0.8849\n",
            "Epoch 58/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.3118 - sparse_categorical_accuracy: 0.8986\n",
            "Epoch 59/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3128 - sparse_categorical_accuracy: 0.9014\n",
            "Epoch 60/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3001 - sparse_categorical_accuracy: 0.9024\n",
            "Epoch 61/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.3303 - sparse_categorical_accuracy: 0.8892\n",
            "Epoch 62/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2756 - sparse_categorical_accuracy: 0.9118\n",
            "Epoch 63/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2884 - sparse_categorical_accuracy: 0.9026\n",
            "Epoch 64/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2899 - sparse_categorical_accuracy: 0.9070\n",
            "Epoch 65/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2864 - sparse_categorical_accuracy: 0.9046\n",
            "Epoch 66/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2715 - sparse_categorical_accuracy: 0.9094\n",
            "Epoch 67/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2849 - sparse_categorical_accuracy: 0.9096\n",
            "Epoch 68/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2619 - sparse_categorical_accuracy: 0.9127\n",
            "Epoch 69/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2684 - sparse_categorical_accuracy: 0.9132\n",
            "Epoch 70/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2735 - sparse_categorical_accuracy: 0.9125\n",
            "Epoch 71/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2753 - sparse_categorical_accuracy: 0.9106\n",
            "Epoch 72/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2532 - sparse_categorical_accuracy: 0.9209\n",
            "Epoch 73/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2468 - sparse_categorical_accuracy: 0.9231\n",
            "Epoch 74/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2565 - sparse_categorical_accuracy: 0.9175\n",
            "Epoch 75/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2412 - sparse_categorical_accuracy: 0.9245\n",
            "2019-09-30 12:31:07.094620\n",
            "train ready\n",
            "fitting\n",
            "Epoch 1/75\n",
            "52/52 [==============================] - 27s 521ms/step - loss: 0.7327 - sparse_categorical_accuracy: 0.7899\n",
            "Epoch 2/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.6881 - sparse_categorical_accuracy: 0.7851\n",
            "Epoch 3/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.6343 - sparse_categorical_accuracy: 0.7993\n",
            "Epoch 4/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.6094 - sparse_categorical_accuracy: 0.8048\n",
            "Epoch 5/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.5734 - sparse_categorical_accuracy: 0.8212\n",
            "Epoch 6/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.5529 - sparse_categorical_accuracy: 0.8243\n",
            "Epoch 7/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.5305 - sparse_categorical_accuracy: 0.8245\n",
            "Epoch 8/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.5352 - sparse_categorical_accuracy: 0.8303\n",
            "Epoch 9/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.5281 - sparse_categorical_accuracy: 0.8370\n",
            "Epoch 10/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.5102 - sparse_categorical_accuracy: 0.8308\n",
            "Epoch 11/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.4877 - sparse_categorical_accuracy: 0.8438\n",
            "Epoch 12/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.4462 - sparse_categorical_accuracy: 0.8558\n",
            "Epoch 13/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.4705 - sparse_categorical_accuracy: 0.8442\n",
            "Epoch 14/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.4427 - sparse_categorical_accuracy: 0.8498\n",
            "Epoch 15/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.4395 - sparse_categorical_accuracy: 0.8594\n",
            "Epoch 16/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.4106 - sparse_categorical_accuracy: 0.8671\n",
            "Epoch 17/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.4460 - sparse_categorical_accuracy: 0.8572\n",
            "Epoch 18/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3827 - sparse_categorical_accuracy: 0.8704\n",
            "Epoch 19/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3879 - sparse_categorical_accuracy: 0.8704\n",
            "Epoch 20/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.3780 - sparse_categorical_accuracy: 0.8776\n",
            "Epoch 21/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.3930 - sparse_categorical_accuracy: 0.8740\n",
            "Epoch 22/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3579 - sparse_categorical_accuracy: 0.8861\n",
            "Epoch 23/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3673 - sparse_categorical_accuracy: 0.8813\n",
            "Epoch 24/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3609 - sparse_categorical_accuracy: 0.8853\n",
            "Epoch 25/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3694 - sparse_categorical_accuracy: 0.8796\n",
            "Epoch 26/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3331 - sparse_categorical_accuracy: 0.8962\n",
            "Epoch 27/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.3351 - sparse_categorical_accuracy: 0.8880\n",
            "Epoch 28/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3340 - sparse_categorical_accuracy: 0.8918\n",
            "Epoch 29/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3207 - sparse_categorical_accuracy: 0.8887\n",
            "Epoch 30/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3205 - sparse_categorical_accuracy: 0.8962\n",
            "Epoch 31/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.3156 - sparse_categorical_accuracy: 0.8911\n",
            "Epoch 32/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3000 - sparse_categorical_accuracy: 0.9029\n",
            "Epoch 33/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3186 - sparse_categorical_accuracy: 0.8940\n",
            "Epoch 34/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2826 - sparse_categorical_accuracy: 0.9123\n",
            "Epoch 35/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2924 - sparse_categorical_accuracy: 0.9048\n",
            "Epoch 36/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2829 - sparse_categorical_accuracy: 0.9041\n",
            "Epoch 37/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2981 - sparse_categorical_accuracy: 0.9014\n",
            "Epoch 38/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2829 - sparse_categorical_accuracy: 0.9060\n",
            "Epoch 39/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2570 - sparse_categorical_accuracy: 0.9171\n",
            "Epoch 40/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2727 - sparse_categorical_accuracy: 0.9166\n",
            "Epoch 41/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2560 - sparse_categorical_accuracy: 0.9156\n",
            "Epoch 42/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2635 - sparse_categorical_accuracy: 0.9113\n",
            "Epoch 43/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.2532 - sparse_categorical_accuracy: 0.9149\n",
            "Epoch 44/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2725 - sparse_categorical_accuracy: 0.9118\n",
            "Epoch 45/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2468 - sparse_categorical_accuracy: 0.9168\n",
            "Epoch 46/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2525 - sparse_categorical_accuracy: 0.9175\n",
            "Epoch 47/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2421 - sparse_categorical_accuracy: 0.9209\n",
            "Epoch 48/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2331 - sparse_categorical_accuracy: 0.9248\n",
            "Epoch 49/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2544 - sparse_categorical_accuracy: 0.9195\n",
            "Epoch 50/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2428 - sparse_categorical_accuracy: 0.9243\n",
            "Epoch 51/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2215 - sparse_categorical_accuracy: 0.9284\n",
            "Epoch 52/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2513 - sparse_categorical_accuracy: 0.9233\n",
            "Epoch 53/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2186 - sparse_categorical_accuracy: 0.9274\n",
            "Epoch 54/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2173 - sparse_categorical_accuracy: 0.9276\n",
            "Epoch 55/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2223 - sparse_categorical_accuracy: 0.9286\n",
            "Epoch 56/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2084 - sparse_categorical_accuracy: 0.9325\n",
            "Epoch 57/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1975 - sparse_categorical_accuracy: 0.9341\n",
            "Epoch 58/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2059 - sparse_categorical_accuracy: 0.9334\n",
            "Epoch 59/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1935 - sparse_categorical_accuracy: 0.9387\n",
            "Epoch 60/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1907 - sparse_categorical_accuracy: 0.9375\n",
            "Epoch 61/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2006 - sparse_categorical_accuracy: 0.9368\n",
            "Epoch 62/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2029 - sparse_categorical_accuracy: 0.9404\n",
            "Epoch 63/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1796 - sparse_categorical_accuracy: 0.9425\n",
            "Epoch 64/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.2053 - sparse_categorical_accuracy: 0.9341\n",
            "Epoch 65/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1878 - sparse_categorical_accuracy: 0.9413\n",
            "Epoch 66/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1937 - sparse_categorical_accuracy: 0.9411\n",
            "Epoch 67/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1717 - sparse_categorical_accuracy: 0.9464\n",
            "Epoch 68/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1864 - sparse_categorical_accuracy: 0.9450\n",
            "Epoch 69/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1759 - sparse_categorical_accuracy: 0.9459\n",
            "Epoch 70/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1908 - sparse_categorical_accuracy: 0.9387\n",
            "Epoch 71/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1599 - sparse_categorical_accuracy: 0.9507\n",
            "Epoch 72/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.1705 - sparse_categorical_accuracy: 0.9450\n",
            "Epoch 73/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1462 - sparse_categorical_accuracy: 0.9526\n",
            "Epoch 74/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1591 - sparse_categorical_accuracy: 0.9483\n",
            "Epoch 75/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1737 - sparse_categorical_accuracy: 0.9471\n",
            "2019-09-30 12:47:02.436557\n",
            "train ready\n",
            "fitting\n",
            "Epoch 1/75\n",
            "52/52 [==============================] - 28s 529ms/step - loss: 0.4649 - sparse_categorical_accuracy: 0.8579\n",
            "Epoch 2/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.4649 - sparse_categorical_accuracy: 0.8555\n",
            "Epoch 3/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.4290 - sparse_categorical_accuracy: 0.8654\n",
            "Epoch 4/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.4086 - sparse_categorical_accuracy: 0.8716\n",
            "Epoch 5/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.4065 - sparse_categorical_accuracy: 0.8697\n",
            "Epoch 6/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.3781 - sparse_categorical_accuracy: 0.8784\n",
            "Epoch 7/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.3636 - sparse_categorical_accuracy: 0.8868\n",
            "Epoch 8/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3544 - sparse_categorical_accuracy: 0.8873\n",
            "Epoch 9/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.3481 - sparse_categorical_accuracy: 0.8889\n",
            "Epoch 10/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.3458 - sparse_categorical_accuracy: 0.8930\n",
            "Epoch 11/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3065 - sparse_categorical_accuracy: 0.9026\n",
            "Epoch 12/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3123 - sparse_categorical_accuracy: 0.8964\n",
            "Epoch 13/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.3209 - sparse_categorical_accuracy: 0.8976\n",
            "Epoch 14/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2964 - sparse_categorical_accuracy: 0.9046\n",
            "Epoch 15/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2959 - sparse_categorical_accuracy: 0.9017\n",
            "Epoch 16/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2690 - sparse_categorical_accuracy: 0.9147\n",
            "Epoch 17/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2988 - sparse_categorical_accuracy: 0.9046\n",
            "Epoch 18/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2658 - sparse_categorical_accuracy: 0.9137\n",
            "Epoch 19/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2593 - sparse_categorical_accuracy: 0.9163\n",
            "Epoch 20/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2509 - sparse_categorical_accuracy: 0.9197\n",
            "Epoch 21/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2621 - sparse_categorical_accuracy: 0.9113\n",
            "Epoch 22/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2420 - sparse_categorical_accuracy: 0.9156\n",
            "Epoch 23/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2554 - sparse_categorical_accuracy: 0.9118\n",
            "Epoch 24/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2459 - sparse_categorical_accuracy: 0.9219\n",
            "Epoch 25/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2218 - sparse_categorical_accuracy: 0.9286\n",
            "Epoch 26/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2207 - sparse_categorical_accuracy: 0.9238\n",
            "Epoch 27/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2309 - sparse_categorical_accuracy: 0.9238\n",
            "Epoch 28/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2371 - sparse_categorical_accuracy: 0.9224\n",
            "Epoch 29/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2274 - sparse_categorical_accuracy: 0.9252\n",
            "Epoch 30/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2281 - sparse_categorical_accuracy: 0.9252\n",
            "Epoch 31/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2043 - sparse_categorical_accuracy: 0.9353\n",
            "Epoch 32/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2050 - sparse_categorical_accuracy: 0.9296\n",
            "Epoch 33/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2035 - sparse_categorical_accuracy: 0.9315\n",
            "Epoch 34/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2199 - sparse_categorical_accuracy: 0.9286\n",
            "Epoch 35/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2134 - sparse_categorical_accuracy: 0.9300\n",
            "Epoch 36/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2025 - sparse_categorical_accuracy: 0.9334\n",
            "Epoch 37/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1884 - sparse_categorical_accuracy: 0.9411\n",
            "Epoch 38/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1966 - sparse_categorical_accuracy: 0.9332\n",
            "Epoch 39/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1836 - sparse_categorical_accuracy: 0.9389\n",
            "Epoch 40/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1949 - sparse_categorical_accuracy: 0.9356\n",
            "Epoch 41/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2089 - sparse_categorical_accuracy: 0.9310\n",
            "Epoch 42/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1682 - sparse_categorical_accuracy: 0.9476\n",
            "Epoch 43/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1653 - sparse_categorical_accuracy: 0.9474\n",
            "Epoch 44/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1563 - sparse_categorical_accuracy: 0.9490\n",
            "Epoch 45/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1824 - sparse_categorical_accuracy: 0.9401\n",
            "Epoch 46/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1897 - sparse_categorical_accuracy: 0.9380\n",
            "Epoch 47/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1738 - sparse_categorical_accuracy: 0.9430\n",
            "Epoch 48/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1621 - sparse_categorical_accuracy: 0.9447\n",
            "Epoch 49/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1707 - sparse_categorical_accuracy: 0.9421\n",
            "Epoch 50/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1831 - sparse_categorical_accuracy: 0.9471\n",
            "Epoch 51/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1557 - sparse_categorical_accuracy: 0.9514\n",
            "Epoch 52/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1486 - sparse_categorical_accuracy: 0.9531\n",
            "Epoch 53/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1528 - sparse_categorical_accuracy: 0.9493\n",
            "Epoch 54/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1629 - sparse_categorical_accuracy: 0.9471\n",
            "Epoch 55/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1458 - sparse_categorical_accuracy: 0.9584\n",
            "Epoch 56/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1377 - sparse_categorical_accuracy: 0.9548\n",
            "Epoch 57/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1512 - sparse_categorical_accuracy: 0.9541\n",
            "Epoch 58/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.1440 - sparse_categorical_accuracy: 0.9517\n",
            "Epoch 59/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1544 - sparse_categorical_accuracy: 0.9464\n",
            "Epoch 60/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1394 - sparse_categorical_accuracy: 0.9543\n",
            "Epoch 61/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1368 - sparse_categorical_accuracy: 0.9567\n",
            "Epoch 62/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1370 - sparse_categorical_accuracy: 0.9519\n",
            "Epoch 63/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1309 - sparse_categorical_accuracy: 0.9594\n",
            "Epoch 64/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1319 - sparse_categorical_accuracy: 0.9563\n",
            "Epoch 65/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1272 - sparse_categorical_accuracy: 0.9591\n",
            "Epoch 66/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1376 - sparse_categorical_accuracy: 0.9558\n",
            "Epoch 67/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1359 - sparse_categorical_accuracy: 0.9567\n",
            "Epoch 68/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1334 - sparse_categorical_accuracy: 0.9596\n",
            "Epoch 69/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1297 - sparse_categorical_accuracy: 0.9587\n",
            "Epoch 70/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1362 - sparse_categorical_accuracy: 0.9582\n",
            "Epoch 71/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1356 - sparse_categorical_accuracy: 0.9572\n",
            "Epoch 72/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1176 - sparse_categorical_accuracy: 0.9637\n",
            "Epoch 73/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1229 - sparse_categorical_accuracy: 0.9637\n",
            "Epoch 74/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.1126 - sparse_categorical_accuracy: 0.9671\n",
            "Epoch 75/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1109 - sparse_categorical_accuracy: 0.9678\n",
            "2019-09-30 13:03:04.200339\n",
            "train ready\n",
            "fitting\n",
            "Epoch 1/75\n",
            "52/52 [==============================] - 28s 534ms/step - loss: 0.3492 - sparse_categorical_accuracy: 0.8916\n",
            "Epoch 2/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.3303 - sparse_categorical_accuracy: 0.9002\n",
            "Epoch 3/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.3081 - sparse_categorical_accuracy: 0.9017\n",
            "Epoch 4/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2916 - sparse_categorical_accuracy: 0.9082\n",
            "Epoch 5/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2776 - sparse_categorical_accuracy: 0.9120\n",
            "Epoch 6/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2662 - sparse_categorical_accuracy: 0.9113\n",
            "Epoch 7/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2625 - sparse_categorical_accuracy: 0.9192\n",
            "Epoch 8/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2527 - sparse_categorical_accuracy: 0.9202\n",
            "Epoch 9/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2356 - sparse_categorical_accuracy: 0.9216\n",
            "Epoch 10/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2547 - sparse_categorical_accuracy: 0.9178\n",
            "Epoch 11/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2324 - sparse_categorical_accuracy: 0.9260\n",
            "Epoch 12/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2192 - sparse_categorical_accuracy: 0.9286\n",
            "Epoch 13/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1836 - sparse_categorical_accuracy: 0.9373\n",
            "Epoch 14/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2103 - sparse_categorical_accuracy: 0.9363\n",
            "Epoch 15/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1849 - sparse_categorical_accuracy: 0.9409\n",
            "Epoch 16/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1950 - sparse_categorical_accuracy: 0.9389\n",
            "Epoch 17/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.2045 - sparse_categorical_accuracy: 0.9332\n",
            "Epoch 18/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2063 - sparse_categorical_accuracy: 0.9315\n",
            "Epoch 19/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.1775 - sparse_categorical_accuracy: 0.9447\n",
            "Epoch 20/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1895 - sparse_categorical_accuracy: 0.9377\n",
            "Epoch 21/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1847 - sparse_categorical_accuracy: 0.9413\n",
            "Epoch 22/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1663 - sparse_categorical_accuracy: 0.9474\n",
            "Epoch 23/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1600 - sparse_categorical_accuracy: 0.9505\n",
            "Epoch 24/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1659 - sparse_categorical_accuracy: 0.9466\n",
            "Epoch 25/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1601 - sparse_categorical_accuracy: 0.9447\n",
            "Epoch 26/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1566 - sparse_categorical_accuracy: 0.9488\n",
            "Epoch 27/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1554 - sparse_categorical_accuracy: 0.9481\n",
            "Epoch 28/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1671 - sparse_categorical_accuracy: 0.9495\n",
            "Epoch 29/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1467 - sparse_categorical_accuracy: 0.9505\n",
            "Epoch 30/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1465 - sparse_categorical_accuracy: 0.9538\n",
            "Epoch 31/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1634 - sparse_categorical_accuracy: 0.9481\n",
            "Epoch 32/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1394 - sparse_categorical_accuracy: 0.9563\n",
            "Epoch 33/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1445 - sparse_categorical_accuracy: 0.9524\n",
            "Epoch 34/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1477 - sparse_categorical_accuracy: 0.9536\n",
            "Epoch 35/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1410 - sparse_categorical_accuracy: 0.9553\n",
            "Epoch 36/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1351 - sparse_categorical_accuracy: 0.9541\n",
            "Epoch 37/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1285 - sparse_categorical_accuracy: 0.9615\n",
            "Epoch 38/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1268 - sparse_categorical_accuracy: 0.9582\n",
            "Epoch 39/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1378 - sparse_categorical_accuracy: 0.9587\n",
            "Epoch 40/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1437 - sparse_categorical_accuracy: 0.9565\n",
            "Epoch 41/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1307 - sparse_categorical_accuracy: 0.9582\n",
            "Epoch 42/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1242 - sparse_categorical_accuracy: 0.9656\n",
            "Epoch 43/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1375 - sparse_categorical_accuracy: 0.9553\n",
            "Epoch 44/75\n",
            "52/52 [==============================] - 12s 228ms/step - loss: 0.1099 - sparse_categorical_accuracy: 0.9654\n",
            "Epoch 45/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1230 - sparse_categorical_accuracy: 0.9613\n",
            "Epoch 46/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1264 - sparse_categorical_accuracy: 0.9575\n",
            "Epoch 47/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1137 - sparse_categorical_accuracy: 0.9635\n",
            "Epoch 48/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1006 - sparse_categorical_accuracy: 0.9683\n",
            "Epoch 49/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1236 - sparse_categorical_accuracy: 0.9603\n",
            "Epoch 50/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1090 - sparse_categorical_accuracy: 0.9637\n",
            "Epoch 51/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1090 - sparse_categorical_accuracy: 0.9671\n",
            "Epoch 52/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1139 - sparse_categorical_accuracy: 0.9627\n",
            "Epoch 53/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1107 - sparse_categorical_accuracy: 0.9685\n",
            "Epoch 54/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0988 - sparse_categorical_accuracy: 0.9700\n",
            "Epoch 55/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1181 - sparse_categorical_accuracy: 0.9623\n",
            "Epoch 56/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1018 - sparse_categorical_accuracy: 0.9661\n",
            "Epoch 57/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0999 - sparse_categorical_accuracy: 0.9663\n",
            "Epoch 58/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.1042 - sparse_categorical_accuracy: 0.9642\n",
            "Epoch 59/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1029 - sparse_categorical_accuracy: 0.9678\n",
            "Epoch 60/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0993 - sparse_categorical_accuracy: 0.9728\n",
            "Epoch 61/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1017 - sparse_categorical_accuracy: 0.9671\n",
            "Epoch 62/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0855 - sparse_categorical_accuracy: 0.9740\n",
            "Epoch 63/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1055 - sparse_categorical_accuracy: 0.9654\n",
            "Epoch 64/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0923 - sparse_categorical_accuracy: 0.9719\n",
            "Epoch 65/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1021 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 66/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0788 - sparse_categorical_accuracy: 0.9760\n",
            "Epoch 67/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0876 - sparse_categorical_accuracy: 0.9736\n",
            "Epoch 68/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0960 - sparse_categorical_accuracy: 0.9678\n",
            "Epoch 69/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0892 - sparse_categorical_accuracy: 0.9724\n",
            "Epoch 70/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0899 - sparse_categorical_accuracy: 0.9724\n",
            "Epoch 71/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0932 - sparse_categorical_accuracy: 0.9716\n",
            "Epoch 72/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0755 - sparse_categorical_accuracy: 0.9784\n",
            "Epoch 73/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0911 - sparse_categorical_accuracy: 0.9712\n",
            "Epoch 74/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0898 - sparse_categorical_accuracy: 0.9726\n",
            "Epoch 75/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0885 - sparse_categorical_accuracy: 0.9712\n",
            "2019-09-30 13:19:08.258780\n",
            "train ready\n",
            "fitting\n",
            "Epoch 1/75\n",
            "52/52 [==============================] - 28s 536ms/step - loss: 0.2533 - sparse_categorical_accuracy: 0.9219\n",
            "Epoch 2/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2270 - sparse_categorical_accuracy: 0.9286\n",
            "Epoch 3/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.2224 - sparse_categorical_accuracy: 0.9332\n",
            "Epoch 4/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1980 - sparse_categorical_accuracy: 0.9375\n",
            "Epoch 5/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1955 - sparse_categorical_accuracy: 0.9339\n",
            "Epoch 6/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1901 - sparse_categorical_accuracy: 0.9377\n",
            "Epoch 7/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1918 - sparse_categorical_accuracy: 0.9411\n",
            "Epoch 8/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1749 - sparse_categorical_accuracy: 0.9406\n",
            "Epoch 9/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1838 - sparse_categorical_accuracy: 0.9380\n",
            "Epoch 10/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1726 - sparse_categorical_accuracy: 0.9469\n",
            "Epoch 11/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1807 - sparse_categorical_accuracy: 0.9425\n",
            "Epoch 12/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1554 - sparse_categorical_accuracy: 0.9505\n",
            "Epoch 13/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1634 - sparse_categorical_accuracy: 0.9450\n",
            "Epoch 14/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1592 - sparse_categorical_accuracy: 0.9505\n",
            "Epoch 15/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1706 - sparse_categorical_accuracy: 0.9478\n",
            "Epoch 16/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1489 - sparse_categorical_accuracy: 0.9488\n",
            "Epoch 17/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1557 - sparse_categorical_accuracy: 0.9466\n",
            "Epoch 18/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1364 - sparse_categorical_accuracy: 0.9572\n",
            "Epoch 19/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1310 - sparse_categorical_accuracy: 0.9582\n",
            "Epoch 20/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1334 - sparse_categorical_accuracy: 0.9594\n",
            "Epoch 21/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1377 - sparse_categorical_accuracy: 0.9565\n",
            "Epoch 22/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1411 - sparse_categorical_accuracy: 0.9531\n",
            "Epoch 23/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1306 - sparse_categorical_accuracy: 0.9577\n",
            "Epoch 24/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1100 - sparse_categorical_accuracy: 0.9659\n",
            "Epoch 25/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1249 - sparse_categorical_accuracy: 0.9611\n",
            "Epoch 26/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1273 - sparse_categorical_accuracy: 0.9584\n",
            "Epoch 27/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1146 - sparse_categorical_accuracy: 0.9611\n",
            "Epoch 28/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1311 - sparse_categorical_accuracy: 0.9567\n",
            "Epoch 29/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1140 - sparse_categorical_accuracy: 0.9630\n",
            "Epoch 30/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1215 - sparse_categorical_accuracy: 0.9615\n",
            "Epoch 31/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1159 - sparse_categorical_accuracy: 0.9637\n",
            "Epoch 32/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0894 - sparse_categorical_accuracy: 0.9743\n",
            "Epoch 33/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.0992 - sparse_categorical_accuracy: 0.9680\n",
            "Epoch 34/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1052 - sparse_categorical_accuracy: 0.9704\n",
            "Epoch 35/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1051 - sparse_categorical_accuracy: 0.9678\n",
            "Epoch 36/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1048 - sparse_categorical_accuracy: 0.9632\n",
            "Epoch 37/75\n",
            "52/52 [==============================] - 12s 228ms/step - loss: 0.1031 - sparse_categorical_accuracy: 0.9673\n",
            "Epoch 38/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1034 - sparse_categorical_accuracy: 0.9651\n",
            "Epoch 39/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1067 - sparse_categorical_accuracy: 0.9700\n",
            "Epoch 40/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0970 - sparse_categorical_accuracy: 0.9724\n",
            "Epoch 41/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0999 - sparse_categorical_accuracy: 0.9685\n",
            "Epoch 42/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.0925 - sparse_categorical_accuracy: 0.9700\n",
            "Epoch 43/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0923 - sparse_categorical_accuracy: 0.9707\n",
            "Epoch 44/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0895 - sparse_categorical_accuracy: 0.9714\n",
            "Epoch 45/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1000 - sparse_categorical_accuracy: 0.9683\n",
            "Epoch 46/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0910 - sparse_categorical_accuracy: 0.9716\n",
            "Epoch 47/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0828 - sparse_categorical_accuracy: 0.9772\n",
            "Epoch 48/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0867 - sparse_categorical_accuracy: 0.9760\n",
            "Epoch 49/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0823 - sparse_categorical_accuracy: 0.9721\n",
            "Epoch 50/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0887 - sparse_categorical_accuracy: 0.9728\n",
            "Epoch 51/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0976 - sparse_categorical_accuracy: 0.9673\n",
            "Epoch 52/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0918 - sparse_categorical_accuracy: 0.9719\n",
            "Epoch 53/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0792 - sparse_categorical_accuracy: 0.9767\n",
            "Epoch 54/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0774 - sparse_categorical_accuracy: 0.9752\n",
            "Epoch 55/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0794 - sparse_categorical_accuracy: 0.9764\n",
            "Epoch 56/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0754 - sparse_categorical_accuracy: 0.9762\n",
            "Epoch 57/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0849 - sparse_categorical_accuracy: 0.9724\n",
            "Epoch 58/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0676 - sparse_categorical_accuracy: 0.9798\n",
            "Epoch 59/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0719 - sparse_categorical_accuracy: 0.9772\n",
            "Epoch 60/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0796 - sparse_categorical_accuracy: 0.9764\n",
            "Epoch 61/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0804 - sparse_categorical_accuracy: 0.9760\n",
            "Epoch 62/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0793 - sparse_categorical_accuracy: 0.9762\n",
            "Epoch 63/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0778 - sparse_categorical_accuracy: 0.9762\n",
            "Epoch 64/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0662 - sparse_categorical_accuracy: 0.9784\n",
            "Epoch 65/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0675 - sparse_categorical_accuracy: 0.9796\n",
            "Epoch 66/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0620 - sparse_categorical_accuracy: 0.9825\n",
            "Epoch 67/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0734 - sparse_categorical_accuracy: 0.9769\n",
            "Epoch 68/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0699 - sparse_categorical_accuracy: 0.9796\n",
            "Epoch 69/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.0760 - sparse_categorical_accuracy: 0.9788\n",
            "Epoch 70/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0685 - sparse_categorical_accuracy: 0.9764\n",
            "Epoch 71/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0695 - sparse_categorical_accuracy: 0.9791\n",
            "Epoch 72/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0679 - sparse_categorical_accuracy: 0.9786\n",
            "Epoch 73/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0618 - sparse_categorical_accuracy: 0.9820\n",
            "Epoch 74/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0657 - sparse_categorical_accuracy: 0.9817\n",
            "Epoch 75/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0674 - sparse_categorical_accuracy: 0.9767\n",
            "2019-09-30 13:35:14.534601\n",
            "train ready\n",
            "fitting\n",
            "Epoch 1/75\n",
            "52/52 [==============================] - 28s 545ms/step - loss: 0.1864 - sparse_categorical_accuracy: 0.9442\n",
            "Epoch 2/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1735 - sparse_categorical_accuracy: 0.9459\n",
            "Epoch 3/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1816 - sparse_categorical_accuracy: 0.9421\n",
            "Epoch 4/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1871 - sparse_categorical_accuracy: 0.9433\n",
            "Epoch 5/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1606 - sparse_categorical_accuracy: 0.9466\n",
            "Epoch 6/75\n",
            "52/52 [==============================] - 12s 224ms/step - loss: 0.1664 - sparse_categorical_accuracy: 0.9469\n",
            "Epoch 7/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1541 - sparse_categorical_accuracy: 0.9495\n",
            "Epoch 8/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1462 - sparse_categorical_accuracy: 0.9589\n",
            "Epoch 9/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1455 - sparse_categorical_accuracy: 0.9522\n",
            "Epoch 10/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1278 - sparse_categorical_accuracy: 0.9611\n",
            "Epoch 11/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1271 - sparse_categorical_accuracy: 0.9594\n",
            "Epoch 12/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1386 - sparse_categorical_accuracy: 0.9567\n",
            "Epoch 13/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1352 - sparse_categorical_accuracy: 0.9560\n",
            "Epoch 14/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1247 - sparse_categorical_accuracy: 0.9560\n",
            "Epoch 15/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1197 - sparse_categorical_accuracy: 0.9630\n",
            "Epoch 16/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1109 - sparse_categorical_accuracy: 0.9668\n",
            "Epoch 17/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1217 - sparse_categorical_accuracy: 0.9613\n",
            "Epoch 18/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1157 - sparse_categorical_accuracy: 0.9639\n",
            "Epoch 19/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1176 - sparse_categorical_accuracy: 0.9618\n",
            "Epoch 20/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1112 - sparse_categorical_accuracy: 0.9654\n",
            "Epoch 21/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1011 - sparse_categorical_accuracy: 0.9671\n",
            "Epoch 22/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1014 - sparse_categorical_accuracy: 0.9685\n",
            "Epoch 23/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1149 - sparse_categorical_accuracy: 0.9630\n",
            "Epoch 24/75\n",
            "52/52 [==============================] - 12s 224ms/step - loss: 0.0986 - sparse_categorical_accuracy: 0.9697\n",
            "Epoch 25/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1024 - sparse_categorical_accuracy: 0.9671\n",
            "Epoch 26/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0944 - sparse_categorical_accuracy: 0.9726\n",
            "Epoch 27/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0973 - sparse_categorical_accuracy: 0.9673\n",
            "Epoch 28/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0995 - sparse_categorical_accuracy: 0.9675\n",
            "Epoch 29/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0914 - sparse_categorical_accuracy: 0.9724\n",
            "Epoch 30/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0800 - sparse_categorical_accuracy: 0.9740\n",
            "Epoch 31/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0938 - sparse_categorical_accuracy: 0.9700\n",
            "Epoch 32/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.0860 - sparse_categorical_accuracy: 0.9724\n",
            "Epoch 33/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0845 - sparse_categorical_accuracy: 0.9719\n",
            "Epoch 34/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0826 - sparse_categorical_accuracy: 0.9772\n",
            "Epoch 35/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0879 - sparse_categorical_accuracy: 0.9745\n",
            "Epoch 36/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0820 - sparse_categorical_accuracy: 0.9712\n",
            "Epoch 37/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0757 - sparse_categorical_accuracy: 0.9760\n",
            "Epoch 38/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0750 - sparse_categorical_accuracy: 0.9767\n",
            "Epoch 39/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0875 - sparse_categorical_accuracy: 0.9724\n",
            "Epoch 40/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0727 - sparse_categorical_accuracy: 0.9793\n",
            "Epoch 41/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0798 - sparse_categorical_accuracy: 0.9748\n",
            "Epoch 42/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0786 - sparse_categorical_accuracy: 0.9752\n",
            "Epoch 43/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0785 - sparse_categorical_accuracy: 0.9767\n",
            "Epoch 44/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0772 - sparse_categorical_accuracy: 0.9750\n",
            "Epoch 45/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0729 - sparse_categorical_accuracy: 0.9764\n",
            "Epoch 46/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0678 - sparse_categorical_accuracy: 0.9796\n",
            "Epoch 47/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0827 - sparse_categorical_accuracy: 0.9764\n",
            "Epoch 48/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0703 - sparse_categorical_accuracy: 0.9769\n",
            "Epoch 49/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0667 - sparse_categorical_accuracy: 0.9808\n",
            "Epoch 50/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0653 - sparse_categorical_accuracy: 0.9815\n",
            "Epoch 51/75\n",
            "52/52 [==============================] - 12s 230ms/step - loss: 0.0729 - sparse_categorical_accuracy: 0.9776\n",
            "Epoch 52/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0698 - sparse_categorical_accuracy: 0.9800\n",
            "Epoch 53/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0650 - sparse_categorical_accuracy: 0.9810\n",
            "Epoch 54/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0594 - sparse_categorical_accuracy: 0.9803\n",
            "Epoch 55/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0622 - sparse_categorical_accuracy: 0.9803\n",
            "Epoch 56/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0643 - sparse_categorical_accuracy: 0.9796\n",
            "Epoch 57/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0632 - sparse_categorical_accuracy: 0.9808\n",
            "Epoch 58/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0583 - sparse_categorical_accuracy: 0.9832\n",
            "Epoch 59/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0574 - sparse_categorical_accuracy: 0.9822\n",
            "Epoch 60/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0609 - sparse_categorical_accuracy: 0.9825\n",
            "Epoch 61/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0690 - sparse_categorical_accuracy: 0.9791\n",
            "Epoch 62/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0608 - sparse_categorical_accuracy: 0.9812\n",
            "Epoch 63/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0557 - sparse_categorical_accuracy: 0.9837\n",
            "Epoch 64/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0504 - sparse_categorical_accuracy: 0.9853\n",
            "Epoch 65/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0529 - sparse_categorical_accuracy: 0.9837\n",
            "Epoch 66/75\n",
            "52/52 [==============================] - 12s 228ms/step - loss: 0.0600 - sparse_categorical_accuracy: 0.9829\n",
            "Epoch 67/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0585 - sparse_categorical_accuracy: 0.9841\n",
            "Epoch 68/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0583 - sparse_categorical_accuracy: 0.9834\n",
            "Epoch 69/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0586 - sparse_categorical_accuracy: 0.9817\n",
            "Epoch 70/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0480 - sparse_categorical_accuracy: 0.9858\n",
            "Epoch 71/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0603 - sparse_categorical_accuracy: 0.9825\n",
            "Epoch 72/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0590 - sparse_categorical_accuracy: 0.9815\n",
            "Epoch 73/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0693 - sparse_categorical_accuracy: 0.9772\n",
            "Epoch 74/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0530 - sparse_categorical_accuracy: 0.9841\n",
            "Epoch 75/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0561 - sparse_categorical_accuracy: 0.9851\n",
            "2019-09-30 13:51:24.051089\n",
            "train ready\n",
            "fitting\n",
            "Epoch 1/75\n",
            "52/52 [==============================] - 28s 547ms/step - loss: 0.1342 - sparse_categorical_accuracy: 0.9577\n",
            "Epoch 2/75\n",
            "52/52 [==============================] - 12s 224ms/step - loss: 0.1356 - sparse_categorical_accuracy: 0.9584\n",
            "Epoch 3/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1147 - sparse_categorical_accuracy: 0.9608\n",
            "Epoch 4/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1263 - sparse_categorical_accuracy: 0.9618\n",
            "Epoch 5/75\n",
            "52/52 [==============================] - 12s 224ms/step - loss: 0.1076 - sparse_categorical_accuracy: 0.9642\n",
            "Epoch 6/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1040 - sparse_categorical_accuracy: 0.9668\n",
            "Epoch 7/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1254 - sparse_categorical_accuracy: 0.9599\n",
            "Epoch 8/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1150 - sparse_categorical_accuracy: 0.9625\n",
            "Epoch 9/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1101 - sparse_categorical_accuracy: 0.9635\n",
            "Epoch 10/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0965 - sparse_categorical_accuracy: 0.9702\n",
            "Epoch 11/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0992 - sparse_categorical_accuracy: 0.9716\n",
            "Epoch 12/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1081 - sparse_categorical_accuracy: 0.9620\n",
            "Epoch 13/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0904 - sparse_categorical_accuracy: 0.9712\n",
            "Epoch 14/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0902 - sparse_categorical_accuracy: 0.9726\n",
            "Epoch 15/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.0931 - sparse_categorical_accuracy: 0.9726\n",
            "Epoch 16/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0835 - sparse_categorical_accuracy: 0.9738\n",
            "Epoch 17/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0825 - sparse_categorical_accuracy: 0.9755\n",
            "Epoch 18/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0885 - sparse_categorical_accuracy: 0.9750\n",
            "Epoch 19/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0801 - sparse_categorical_accuracy: 0.9750\n",
            "Epoch 20/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0802 - sparse_categorical_accuracy: 0.9743\n",
            "Epoch 21/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0804 - sparse_categorical_accuracy: 0.9755\n",
            "Epoch 22/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0727 - sparse_categorical_accuracy: 0.9764\n",
            "Epoch 23/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0710 - sparse_categorical_accuracy: 0.9781\n",
            "Epoch 24/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0680 - sparse_categorical_accuracy: 0.9803\n",
            "Epoch 25/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0730 - sparse_categorical_accuracy: 0.9762\n",
            "Epoch 26/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0741 - sparse_categorical_accuracy: 0.9791\n",
            "Epoch 27/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0852 - sparse_categorical_accuracy: 0.9738\n",
            "Epoch 28/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0788 - sparse_categorical_accuracy: 0.9736\n",
            "Epoch 29/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.0637 - sparse_categorical_accuracy: 0.9827\n",
            "Epoch 30/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0700 - sparse_categorical_accuracy: 0.9764\n",
            "Epoch 31/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0680 - sparse_categorical_accuracy: 0.9779\n",
            "Epoch 32/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0618 - sparse_categorical_accuracy: 0.9803\n",
            "Epoch 33/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0691 - sparse_categorical_accuracy: 0.9781\n",
            "Epoch 34/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0552 - sparse_categorical_accuracy: 0.9822\n",
            "Epoch 35/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0758 - sparse_categorical_accuracy: 0.9767\n",
            "Epoch 36/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0598 - sparse_categorical_accuracy: 0.9820\n",
            "Epoch 37/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0551 - sparse_categorical_accuracy: 0.9829\n",
            "Epoch 38/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0726 - sparse_categorical_accuracy: 0.9786\n",
            "Epoch 39/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0487 - sparse_categorical_accuracy: 0.9861\n",
            "Epoch 40/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0608 - sparse_categorical_accuracy: 0.9808\n",
            "Epoch 41/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.0586 - sparse_categorical_accuracy: 0.9849\n",
            "Epoch 42/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0557 - sparse_categorical_accuracy: 0.9820\n",
            "Epoch 43/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0695 - sparse_categorical_accuracy: 0.9769\n",
            "Epoch 44/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0527 - sparse_categorical_accuracy: 0.9841\n",
            "Epoch 45/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0556 - sparse_categorical_accuracy: 0.9817\n",
            "Epoch 46/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0601 - sparse_categorical_accuracy: 0.9812\n",
            "Epoch 47/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0580 - sparse_categorical_accuracy: 0.9812\n",
            "Epoch 48/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0634 - sparse_categorical_accuracy: 0.9808\n",
            "Epoch 49/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0488 - sparse_categorical_accuracy: 0.9863\n",
            "Epoch 50/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0586 - sparse_categorical_accuracy: 0.9829\n",
            "Epoch 51/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.0584 - sparse_categorical_accuracy: 0.9827\n",
            "Epoch 52/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0491 - sparse_categorical_accuracy: 0.9856\n",
            "Epoch 53/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0494 - sparse_categorical_accuracy: 0.9861\n",
            "Epoch 54/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0551 - sparse_categorical_accuracy: 0.9832\n",
            "Epoch 55/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0460 - sparse_categorical_accuracy: 0.9894\n",
            "Epoch 56/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0594 - sparse_categorical_accuracy: 0.9841\n",
            "Epoch 57/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0496 - sparse_categorical_accuracy: 0.9841\n",
            "Epoch 58/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0442 - sparse_categorical_accuracy: 0.9887\n",
            "Epoch 59/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0453 - sparse_categorical_accuracy: 0.9870\n",
            "Epoch 60/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0452 - sparse_categorical_accuracy: 0.9868\n",
            "Epoch 61/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0466 - sparse_categorical_accuracy: 0.9875\n",
            "Epoch 62/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0415 - sparse_categorical_accuracy: 0.9880\n",
            "Epoch 63/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0469 - sparse_categorical_accuracy: 0.9858\n",
            "Epoch 64/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0460 - sparse_categorical_accuracy: 0.9858\n",
            "Epoch 65/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0468 - sparse_categorical_accuracy: 0.9877\n",
            "Epoch 66/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0471 - sparse_categorical_accuracy: 0.9873\n",
            "Epoch 67/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0439 - sparse_categorical_accuracy: 0.9873\n",
            "Epoch 68/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0448 - sparse_categorical_accuracy: 0.9880\n",
            "Epoch 69/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0454 - sparse_categorical_accuracy: 0.9861\n",
            "Epoch 70/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0351 - sparse_categorical_accuracy: 0.9918\n",
            "Epoch 71/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0511 - sparse_categorical_accuracy: 0.9841\n",
            "Epoch 72/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0478 - sparse_categorical_accuracy: 0.9865\n",
            "Epoch 73/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0488 - sparse_categorical_accuracy: 0.9849\n",
            "Epoch 74/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0511 - sparse_categorical_accuracy: 0.9858\n",
            "Epoch 75/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0420 - sparse_categorical_accuracy: 0.9882\n",
            "2019-09-30 14:07:39.316209\n",
            "train ready\n",
            "fitting\n",
            "Epoch 1/75\n",
            "52/52 [==============================] - 29s 563ms/step - loss: 0.1156 - sparse_categorical_accuracy: 0.9637\n",
            "Epoch 2/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.1049 - sparse_categorical_accuracy: 0.9671\n",
            "Epoch 3/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0906 - sparse_categorical_accuracy: 0.9716\n",
            "Epoch 4/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.1010 - sparse_categorical_accuracy: 0.9661\n",
            "Epoch 5/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0808 - sparse_categorical_accuracy: 0.9743\n",
            "Epoch 6/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0842 - sparse_categorical_accuracy: 0.9721\n",
            "Epoch 7/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0905 - sparse_categorical_accuracy: 0.9702\n",
            "Epoch 8/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0859 - sparse_categorical_accuracy: 0.9733\n",
            "Epoch 9/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0757 - sparse_categorical_accuracy: 0.9764\n",
            "Epoch 10/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.0696 - sparse_categorical_accuracy: 0.9791\n",
            "Epoch 11/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0763 - sparse_categorical_accuracy: 0.9762\n",
            "Epoch 12/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0684 - sparse_categorical_accuracy: 0.9791\n",
            "Epoch 13/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0744 - sparse_categorical_accuracy: 0.9760\n",
            "Epoch 14/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0772 - sparse_categorical_accuracy: 0.9779\n",
            "Epoch 15/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0729 - sparse_categorical_accuracy: 0.9748\n",
            "Epoch 16/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0693 - sparse_categorical_accuracy: 0.9793\n",
            "Epoch 17/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.0720 - sparse_categorical_accuracy: 0.9786\n",
            "Epoch 18/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0708 - sparse_categorical_accuracy: 0.9767\n",
            "Epoch 19/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0756 - sparse_categorical_accuracy: 0.9743\n",
            "Epoch 20/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0619 - sparse_categorical_accuracy: 0.9805\n",
            "Epoch 21/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0616 - sparse_categorical_accuracy: 0.9798\n",
            "Epoch 22/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0645 - sparse_categorical_accuracy: 0.9788\n",
            "Epoch 23/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0612 - sparse_categorical_accuracy: 0.9805\n",
            "Epoch 24/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0598 - sparse_categorical_accuracy: 0.9837\n",
            "Epoch 25/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0548 - sparse_categorical_accuracy: 0.9820\n",
            "Epoch 26/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0546 - sparse_categorical_accuracy: 0.9827\n",
            "Epoch 27/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0567 - sparse_categorical_accuracy: 0.9834\n",
            "Epoch 28/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0535 - sparse_categorical_accuracy: 0.9825\n",
            "Epoch 29/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0608 - sparse_categorical_accuracy: 0.9810\n",
            "Epoch 30/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0496 - sparse_categorical_accuracy: 0.9868\n",
            "Epoch 31/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.0525 - sparse_categorical_accuracy: 0.9839\n",
            "Epoch 32/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0634 - sparse_categorical_accuracy: 0.9815\n",
            "Epoch 33/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0533 - sparse_categorical_accuracy: 0.9846\n",
            "Epoch 34/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0559 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 35/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0498 - sparse_categorical_accuracy: 0.9877\n",
            "Epoch 36/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0542 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 37/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0475 - sparse_categorical_accuracy: 0.9841\n",
            "Epoch 38/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0475 - sparse_categorical_accuracy: 0.9861\n",
            "Epoch 39/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0472 - sparse_categorical_accuracy: 0.9863\n",
            "Epoch 40/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.0462 - sparse_categorical_accuracy: 0.9877\n",
            "Epoch 41/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0471 - sparse_categorical_accuracy: 0.9846\n",
            "Epoch 42/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0415 - sparse_categorical_accuracy: 0.9875\n",
            "Epoch 43/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0434 - sparse_categorical_accuracy: 0.9870\n",
            "Epoch 44/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0456 - sparse_categorical_accuracy: 0.9858\n",
            "Epoch 45/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0514 - sparse_categorical_accuracy: 0.9853\n",
            "Epoch 46/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0420 - sparse_categorical_accuracy: 0.9846\n",
            "Epoch 47/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0481 - sparse_categorical_accuracy: 0.9853\n",
            "Epoch 48/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0456 - sparse_categorical_accuracy: 0.9834\n",
            "Epoch 49/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0463 - sparse_categorical_accuracy: 0.9856\n",
            "Epoch 50/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0469 - sparse_categorical_accuracy: 0.9861\n",
            "Epoch 51/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0422 - sparse_categorical_accuracy: 0.9863\n",
            "Epoch 52/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0416 - sparse_categorical_accuracy: 0.9887\n",
            "Epoch 53/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0413 - sparse_categorical_accuracy: 0.9882\n",
            "Epoch 54/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0411 - sparse_categorical_accuracy: 0.9887\n",
            "Epoch 55/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0386 - sparse_categorical_accuracy: 0.9892\n",
            "Epoch 56/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.0387 - sparse_categorical_accuracy: 0.9897\n",
            "Epoch 57/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0436 - sparse_categorical_accuracy: 0.9858\n",
            "Epoch 58/75\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.0442 - sparse_categorical_accuracy: 0.9887\n",
            "Epoch 59/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0456 - sparse_categorical_accuracy: 0.9865\n",
            "Epoch 60/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0345 - sparse_categorical_accuracy: 0.9918\n",
            "Epoch 61/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0433 - sparse_categorical_accuracy: 0.9875\n",
            "Epoch 62/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0370 - sparse_categorical_accuracy: 0.9904\n",
            "Epoch 63/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0328 - sparse_categorical_accuracy: 0.9913\n",
            "Epoch 64/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0376 - sparse_categorical_accuracy: 0.9882\n",
            "Epoch 65/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0342 - sparse_categorical_accuracy: 0.9892\n",
            "Epoch 66/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0353 - sparse_categorical_accuracy: 0.9906\n",
            "Epoch 67/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0445 - sparse_categorical_accuracy: 0.9873\n",
            "Epoch 68/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0364 - sparse_categorical_accuracy: 0.9911\n",
            "Epoch 69/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0380 - sparse_categorical_accuracy: 0.9875\n",
            "Epoch 70/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0357 - sparse_categorical_accuracy: 0.9897\n",
            "Epoch 71/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0473 - sparse_categorical_accuracy: 0.9858\n",
            "Epoch 72/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0368 - sparse_categorical_accuracy: 0.9877\n",
            "Epoch 73/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0362 - sparse_categorical_accuracy: 0.9897\n",
            "Epoch 74/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0361 - sparse_categorical_accuracy: 0.9892\n",
            "Epoch 75/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0398 - sparse_categorical_accuracy: 0.9882\n",
            "2019-09-30 14:23:57.850847\n",
            "train ready\n",
            "fitting\n",
            "Epoch 1/75\n",
            "52/52 [==============================] - 29s 562ms/step - loss: 0.0964 - sparse_categorical_accuracy: 0.9731\n",
            "Epoch 2/75\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0882 - sparse_categorical_accuracy: 0.9709\n",
            "Epoch 3/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0780 - sparse_categorical_accuracy: 0.9752\n",
            "Epoch 4/75\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0756 - sparse_categorical_accuracy: 0.9767\n",
            "Epoch 5/75\n",
            "32/52 [=================>............] - ETA: 4s - loss: 0.0659 - sparse_categorical_accuracy: 0.9793"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b529168de74c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mtrain_xy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_xy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m       \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m   )\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m             validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m     batch_size = self._validate_or_infer_batch_size(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_distributed.py\u001b[0m in \u001b[0;36mfit_distributed\u001b[0;34m(model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m    129\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     return training_arrays.fit_loop(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_distributed.py\u001b[0m in \u001b[0;36mexperimental_tpu_fit_loop\u001b[0;34m(model, dataset, epochs, verbose, callbacks, initial_epoch, steps_per_epoch, val_dataset, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0mprev_step_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         logging.warning('Your dataset iterator ran out of data; '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m   3008\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get value inside Tensorflow graph function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3009\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3010\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3011\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3012\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}